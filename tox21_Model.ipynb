{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tox21_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V49aUWwS3zmZ",
        "colab_type": "text"
      },
      "source": [
        "# Preparación de la Notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWFr0nrHzSxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c45d8713-a194-4c9c-a89e-e5fd2cfd7e2f"
      },
      "source": [
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-22 17:40:16--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n",
            "--2020-07-22 17:40:16--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88867207 (85M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  51%[=========>          ]  43.35M   217MB/s               \r        Miniconda3-  87%[================>   ]  74.54M   186MB/s               \rMiniconda3-latest-L 100%[===================>]  84.75M   181MB/s    in 0.5s    \n",
            "\n",
            "2020-07-22 17:40:17 (181 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [88867207/88867207]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2020.4.5.1=py37_0\n",
            "    - cffi==1.14.0=py37he30daa8_1\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.1=py37h7b6447c_0\n",
            "    - conda==4.8.3=py37_0\n",
            "    - cryptography==2.9.2=py37h1ba5d50_0\n",
            "    - idna==2.9=py_1\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.3=he6710b0_1\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_1\n",
            "    - openssl==1.1.1g=h7b6447c_0\n",
            "    - pip==20.0.2=py37_3\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.20=py_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.7=hcff3b4d_5\n",
            "    - readline==8.0=h7b6447c_0\n",
            "    - requests==2.23.0=py37_0\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==46.4.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h62c20be_1\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.46.0=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2020.4.5.1-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37he30daa8_1\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.3-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.1-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.9.2-py37h1ba5d50_0\n",
            "  idna               pkgs/main/noarch::idna-2.9-py_1\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_1\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1g-h7b6447c_0\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_3\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.20-py_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.7-hcff3b4d_5\n",
            "  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0\n",
            "  requests           pkgs/main/linux-64::requests-2.23.0-py37_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-46.4.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h62c20be_1\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.46.0-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m31.810s\n",
            "user\t0m14.284s\n",
            "sys\t0m4.856s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.72.0               |   py37h9de70de_0         316 KB  conda-forge\n",
            "    boost-cpp-1.72.0           |       h7b93d67_2        16.3 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    ca-certificates-2020.6.20  |       hecda079_0         145 KB  conda-forge\n",
            "    cairo-1.16.0               |    h3fc0475_1005         1.5 MB  conda-forge\n",
            "    certifi-2020.6.20          |   py37hc8dfbb8_0         151 KB  conda-forge\n",
            "    conda-4.8.3                |   py37hc8dfbb8_1         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h1056068_1002         365 KB  conda-forge\n",
            "    freetype-2.10.2            |       he06d7ca_0         905 KB  conda-forge\n",
            "    glib-2.65.0                |       h3eb4bd4_0         2.9 MB\n",
            "    icu-67.1                   |       he1b5a44_0        12.9 MB  conda-forge\n",
            "    jpeg-9d                    |       h516909a_0         266 KB  conda-forge\n",
            "    libblas-3.8.0              |      17_openblas          11 KB  conda-forge\n",
            "    libcblas-3.8.0             |      17_openblas          11 KB  conda-forge\n",
            "    libgfortran-ng-7.5.0       |       hdf63c60_6         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1006         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      17_openblas          11 KB  conda-forge\n",
            "    libopenblas-0.3.10         |pthreads_hb3c22a3_3         7.8 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_1         308 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hc7e4089_6         668 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libwebp-base-1.1.0         |       h516909a_3         845 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       h72b56ed_1         1.3 MB  conda-forge\n",
            "    lz4-c-1.9.2                |       he1b5a44_1         226 KB  conda-forge\n",
            "    numpy-1.19.0               |   py37h8960a57_0         5.2 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1g             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-1.0.5               |   py37h0da4684_0        10.1 MB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pillow-7.0.0               |   py37hb39fc2d_0         598 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.19.1             |   py37h01af8b0_3          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
            "    pytz-2020.1                |     pyh9f0ad1d_0         227 KB  conda-forge\n",
            "    rdkit-2020.03.4            |   py37hdd87690_0        24.6 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.5                 |       h6597ccf_1         428 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        99.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.72.0-py37h9de70de_0\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.72.0-h7b93d67_2\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-h3fc0475_1005\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h1056068_1002\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.2-he06d7ca_0\n",
            "  glib               pkgs/main/linux-64::glib-2.65.0-h3eb4bd4_0\n",
            "  icu                conda-forge/linux-64::icu-67.1-he1b5a44_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h516909a_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-17_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-17_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-hdf63c60_6\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1006\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-17_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.10-pthreads_hb3c22a3_3\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_1\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc7e4089_6\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.1.0-h516909a_3\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-h72b56ed_1\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.9.2-he1b5a44_1\n",
            "  numpy              conda-forge/linux-64::numpy-1.19.0-py37h8960a57_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.0.5-py37h0da4684_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-7.0.0-py37hb39fc2d_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.19.1-py37h01af8b0_3\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
            "  pytz               conda-forge/noarch::pytz-2020.1-pyh9f0ad1d_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2020.03.4-py37hdd87690_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.5-h6597ccf_1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.6.20-hecda079_0\n",
            "  certifi              pkgs/main::certifi-2020.4.5.1-py37_0 --> conda-forge::certifi-2020.6.20-py37hc8dfbb8_0\n",
            "  conda                       pkgs/main::conda-4.8.3-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  openssl              pkgs/main::openssl-1.1.1g-h7b6447c_0 --> conda-forge::openssl-1.1.1g-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m42.179s\n",
            "user\t0m36.228s\n",
            "sys\t0m4.661s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-vdXM4u0Cv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "\n",
        "#!apt install  openbabel\n",
        "\n",
        "import rdkit\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit.Chem import PandasTools\n",
        "\n",
        "!pip install git+https://github.com/autonomio/talos@1.0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRlOCTBGcoRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "881d291a-8402-4f77-fbc4-a3efb7a10f77"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My Drive/finalRedes\n",
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/My Drive/finalRedes'\n",
            "/content/drive/.shortcut-targets-by-id/1vnOFBVFFehrvQ_ZlIpZVR7M-VhQvq5p-/finalRedes\n",
            "Descriptores_nr_ar.csv\t\t   tox21_SCAN4_activations\n",
            "Descriptores_nr_er.csv\t\t   tox21_SCAN4_activations_firstNeuron\n",
            "Descriptores_test.csv\t\t   tox21_SCAN4_activations_initializers\n",
            "Descriptores_test_new.csv\t   tox21_SCAN4_activations_initializers2\n",
            "logs\t\t\t\t   tox21_SCAN4_relu_dropANDhiddenLayers\n",
            "Miniconda3-latest-Linux-x86_64.sh  tox21_SCAN4_relu_dropout\n",
            "nr_ar_activity.txt\t\t   tox21_SCAN4_relu_dropout_bathcNorm\n",
            "nr-ar.sdf\t\t\t   tox21_SCAN4_relu_firstNeuron\n",
            "nr_ar_test_activity.txt\t\t   tox21_SCAN4_relu_kernelReg\n",
            "nr_er_activity.txt\t\t   tox21_SCAN4_relu_kernelReg_accuracy\n",
            "nr-er.sdf\t\t\t   tox21_SCAN4_relu_shapes\n",
            "nr_er_test_activity.txt\t\t   tox21_SCAN_nr_er_dropout_activations\n",
            "nr_er_test_new_activity.txt\t   tox21_SCAN_nr_er_first_neuron_shape\n",
            "tox21_SCAN1\t\t\t   tox21_SCAN_nr_er_FNeu_DO\n",
            "tox21_SCAN2\t\t\t   tox21_SCAN_nr_er_regularizacion\n",
            "tox21_SCAN3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOzbHfqP4ChN",
        "colab_type": "text"
      },
      "source": [
        "# Preparación de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwM2ExRQ4YiT",
        "colab_type": "text"
      },
      "source": [
        "Archivo con Descriptores calculados para el efecto toxico NR-ER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTgQah_nh_ro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "a77195a1-9af7-4ec3-9786-47c8ac4184f9"
      },
      "source": [
        "desc_path = 'Descriptores_nr_er.csv' #Este archivo se obtuvo con la notebook tox21_DescriptorsCalc\n",
        "descriptores = pd.read_csv(desc_path)\n",
        "descriptores"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>abonds</th>\n",
              "      <th>atoms</th>\n",
              "      <th>bonds</th>\n",
              "      <th>cansmi</th>\n",
              "      <th>cansmiNS</th>\n",
              "      <th>dbonds</th>\n",
              "      <th>formula</th>\n",
              "      <th>HBA1</th>\n",
              "      <th>HBA2</th>\n",
              "      <th>HBD</th>\n",
              "      <th>InChI</th>\n",
              "      <th>InChIKey</th>\n",
              "      <th>L5</th>\n",
              "      <th>logP</th>\n",
              "      <th>MP</th>\n",
              "      <th>MR</th>\n",
              "      <th>MW</th>\n",
              "      <th>nF</th>\n",
              "      <th>rotors</th>\n",
              "      <th>s</th>\n",
              "      <th>sbonds</th>\n",
              "      <th>smarts</th>\n",
              "      <th>tbonds</th>\n",
              "      <th>title</th>\n",
              "      <th>TPSA</th>\n",
              "      <th>CHARGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.7767</td>\n",
              "      <td>133.0267</td>\n",
              "      <td>86.5125</td>\n",
              "      <td>378.312159</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>18.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.1944</td>\n",
              "      <td>139.7661</td>\n",
              "      <td>140.9350</td>\n",
              "      <td>457.603800</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.93</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>17.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.5770</td>\n",
              "      <td>298.4234</td>\n",
              "      <td>73.7772</td>\n",
              "      <td>253.262640</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>129.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0394</td>\n",
              "      <td>202.9346</td>\n",
              "      <td>133.0344</td>\n",
              "      <td>494.475279</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.9826</td>\n",
              "      <td>8.9656</td>\n",
              "      <td>145.4004</td>\n",
              "      <td>474.855700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.69</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7692</th>\n",
              "      <td>7692</td>\n",
              "      <td>6.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.3850</td>\n",
              "      <td>179.0045</td>\n",
              "      <td>46.8274</td>\n",
              "      <td>170.232100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.74</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7693</th>\n",
              "      <td>7693</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1217</td>\n",
              "      <td>82.7273</td>\n",
              "      <td>35.6454</td>\n",
              "      <td>102.158140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7694</th>\n",
              "      <td>7694</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1217</td>\n",
              "      <td>82.7273</td>\n",
              "      <td>35.6454</td>\n",
              "      <td>102.158140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7695</th>\n",
              "      <td>7695</td>\n",
              "      <td>6.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.4449</td>\n",
              "      <td>42.3956</td>\n",
              "      <td>73.9150</td>\n",
              "      <td>291.260621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.41</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7696</th>\n",
              "      <td>7696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.9721</td>\n",
              "      <td>84.2486</td>\n",
              "      <td>101.6010</td>\n",
              "      <td>398.558340</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7697 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  abonds  atoms  bonds  ...  tbonds  title    TPSA  CHARGE\n",
              "0              0    11.0   42.0   44.0  ...     0.0    0.0   45.15       0\n",
              "1              1    18.0   69.0   73.0  ...     0.0    0.0   30.93       0\n",
              "2              2    17.0   30.0   32.0  ...     0.0    0.0  129.62       0\n",
              "3              3    12.0   59.0   61.0  ...     0.0    0.0   48.78       0\n",
              "4              4     0.0   92.0   91.0  ...     0.0    0.0   27.69       1\n",
              "...          ...     ...    ...    ...  ...     ...    ...     ...     ...\n",
              "7692        7692     6.0   21.0   21.0  ...     0.0    0.0   80.74       0\n",
              "7693        7693     0.0   12.0   12.0  ...     0.0    0.0   56.15       0\n",
              "7694        7694     0.0   12.0   12.0  ...     0.0    0.0   56.15       0\n",
              "7695        7695     6.0   32.0   32.0  ...     0.0    0.0  115.41       0\n",
              "7696        7696     0.0   50.0   49.0  ...     0.0    0.0  195.30       0\n",
              "\n",
              "[7697 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ8DL0lypBbm",
        "colab_type": "text"
      },
      "source": [
        "Obtenemos el vector de clases segun las actividades\n",
        "\n",
        "0 : inactivo\n",
        "\n",
        "1 : activo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zSsSNzAkB57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b87881e-8d81-4d54-8dad-a8a98b1dd251"
      },
      "source": [
        "#Read target.\n",
        "actives_f = open(\"nr_er_activity.txt\", \"r\") #Este archivo se obtuvo de la columna de Actividad del SDF.\n",
        "activity = []\n",
        "for x in actives_f:\n",
        "  activity.append(x[0])\n",
        "#activity = activity[1:]\n",
        "activity = [int(i) for i in activity]\n",
        "y = np.array(activity)\n",
        "print(y.shape)\n",
        "actives_f.close()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7697,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q3yDN2ApOO2",
        "colab_type": "text"
      },
      "source": [
        "Vemos la distribucion de Activos e Inactivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9_vzXqDSx-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "a07b8ff6-7b21-4300-8fe0-f910f61d57c2"
      },
      "source": [
        "#Visualizar activos vs inactivos: \n",
        "activos = sum(y)\n",
        "inactivos = sum((y == 0)*1)\n",
        "indices = ['Activos','Inactivos']\n",
        "print('Proporcion de activos en el dataset:', activos/(activos+inactivos))\n",
        "activity_df = pd.DataFrame(data = [activos, inactivos], columns = ['NR-ER'], index = indices)\n",
        "activity_df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proporcion de activos en el dataset: 0.1217357411978693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NR-ER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Activos</th>\n",
              "      <td>937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Inactivos</th>\n",
              "      <td>6760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           NR-ER\n",
              "Activos      937\n",
              "Inactivos   6760"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6H4Zs-O4hrr",
        "colab_type": "text"
      },
      "source": [
        "Train - Validation split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR3cKhIDjuay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d440a954-e17d-4c5e-cd3a-4345aa869fe5"
      },
      "source": [
        "#Train-Val Split. \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(descriptores.values, y, test_size =0.1,random_state = 42, stratify=activity)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6927, 27)\n",
            "(770, 27)\n",
            "(6927,)\n",
            "(770,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU6iWVEc-mjg",
        "colab_type": "text"
      },
      "source": [
        "# Procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6Qrx06K-txz",
        "colab_type": "text"
      },
      "source": [
        "Normalización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ws3FfOEj2ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "48869d05-a934-44e7-94ba-33b900c3719a"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "desc_scaler = StandardScaler()\n",
        "X_train = desc_scaler.fit_transform(X_train)\n",
        "Scaled_descriptors = pd.DataFrame(X_train, columns=descriptores.columns)\n",
        "Scaled_descriptors.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>abonds</th>\n",
              "      <th>atoms</th>\n",
              "      <th>bonds</th>\n",
              "      <th>cansmi</th>\n",
              "      <th>cansmiNS</th>\n",
              "      <th>dbonds</th>\n",
              "      <th>formula</th>\n",
              "      <th>HBA1</th>\n",
              "      <th>HBA2</th>\n",
              "      <th>HBD</th>\n",
              "      <th>InChI</th>\n",
              "      <th>InChIKey</th>\n",
              "      <th>L5</th>\n",
              "      <th>logP</th>\n",
              "      <th>MP</th>\n",
              "      <th>MR</th>\n",
              "      <th>MW</th>\n",
              "      <th>nF</th>\n",
              "      <th>rotors</th>\n",
              "      <th>s</th>\n",
              "      <th>sbonds</th>\n",
              "      <th>smarts</th>\n",
              "      <th>tbonds</th>\n",
              "      <th>title</th>\n",
              "      <th>TPSA</th>\n",
              "      <th>CHARGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.867422</td>\n",
              "      <td>0.061204</td>\n",
              "      <td>0.681038</td>\n",
              "      <td>0.628320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.267463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.776294</td>\n",
              "      <td>-0.191243</td>\n",
              "      <td>-0.088211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631796</td>\n",
              "      <td>-0.323901</td>\n",
              "      <td>0.492766</td>\n",
              "      <td>0.159438</td>\n",
              "      <td>-0.148362</td>\n",
              "      <td>0.746655</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.686063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.168185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.474732</td>\n",
              "      <td>0.113714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.218618</td>\n",
              "      <td>0.061204</td>\n",
              "      <td>-0.696640</td>\n",
              "      <td>-0.695395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.890852</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.664650</td>\n",
              "      <td>-0.746224</td>\n",
              "      <td>-0.088211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.607300</td>\n",
              "      <td>-0.709506</td>\n",
              "      <td>-0.772663</td>\n",
              "      <td>-0.858691</td>\n",
              "      <td>-0.148362</td>\n",
              "      <td>-0.522930</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.697721</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.168185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.677815</td>\n",
              "      <td>0.113714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.849975</td>\n",
              "      <td>0.061204</td>\n",
              "      <td>-0.554122</td>\n",
              "      <td>-0.558459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.267463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.520556</td>\n",
              "      <td>-0.191243</td>\n",
              "      <td>-0.636224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.466974</td>\n",
              "      <td>-0.482779</td>\n",
              "      <td>-0.583903</td>\n",
              "      <td>-0.568211</td>\n",
              "      <td>-0.148362</td>\n",
              "      <td>-0.311333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.598879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.168185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.421236</td>\n",
              "      <td>0.113714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.431886</td>\n",
              "      <td>0.061204</td>\n",
              "      <td>0.015952</td>\n",
              "      <td>-0.010714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.890852</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.127869</td>\n",
              "      <td>-0.191243</td>\n",
              "      <td>1.007816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.138689</td>\n",
              "      <td>-0.095840</td>\n",
              "      <td>-0.162152</td>\n",
              "      <td>-0.283662</td>\n",
              "      <td>-0.148362</td>\n",
              "      <td>0.323460</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.168185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.136819</td>\n",
              "      <td>0.113714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.397894</td>\n",
              "      <td>-0.992992</td>\n",
              "      <td>0.633532</td>\n",
              "      <td>0.719611</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.979316</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.560152</td>\n",
              "      <td>-0.468734</td>\n",
              "      <td>-0.636224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.756467</td>\n",
              "      <td>0.446433</td>\n",
              "      <td>0.420815</td>\n",
              "      <td>0.225386</td>\n",
              "      <td>-0.148362</td>\n",
              "      <td>-0.946125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.982589</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.168185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.444546</td>\n",
              "      <td>0.113714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0    abonds     atoms  ...  title      TPSA    CHARGE\n",
              "0   -0.867422  0.061204  0.681038  ...    0.0 -0.474732  0.113714\n",
              "1   -0.218618  0.061204 -0.696640  ...    0.0 -0.677815  0.113714\n",
              "2    0.849975  0.061204 -0.554122  ...    0.0 -0.421236  0.113714\n",
              "3   -0.431886  0.061204  0.015952  ...    0.0 -0.136819  0.113714\n",
              "4   -1.397894 -0.992992  0.633532  ...    0.0 -0.444546  0.113714\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URdOocrrkWM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Validation Scale:\n",
        "X_val = desc_scaler.transform(X_val)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfhyZoJm-8sx",
        "colab_type": "text"
      },
      "source": [
        "Paquetes de procesamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UOZbOaZkn2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.metrics import AUC, TruePositives, FalsePositives, FalseNegatives\n",
        "from keras.layers import Dense, Flatten, Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization, PReLU, ELU, LeakyReLU\n",
        "from keras.layers import Conv2D, AveragePooling2D, BatchNormalization, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from keras import optimizers, initializers\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.initializers import glorot_uniform, he_uniform, uniform, Constant\n",
        "from keras.constraints import maxnorm\n",
        "from keras.regularizers import l2\n",
        "\n",
        "import talos\n",
        "import datetime\n",
        "from keras.callbacks import TensorBoard\n",
        "from talos.model.network_shape import network_shape\n",
        "from talos.model.normalizers import lr_normalizer\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau, ModelCheckpoint"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6FqjJTeQWq2",
        "colab_type": "text"
      },
      "source": [
        "## Busqueda de Hiperparametros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrgVv1NJTKOJ",
        "colab_type": "text"
      },
      "source": [
        "Busqueda de Hiperparametros con Talos Scan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6wjJfAxzDQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def tox21_model(x,y,params): \n",
        "    model = Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    model.add(Dense(params['first_neuron'], input_shape = (X_train.shape[1],), kernel_initializer='he_uniform', activation = 'tanh'))\n",
        "    # Input Dropout layer\n",
        "    if(params['dropout']>0):\n",
        "        model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # Hidden layers\n",
        "    layer_neurons = network_shape(params,1)\n",
        "\n",
        "    for i in range(params['hidden_layers']):\n",
        "\n",
        "        # Normalization layer\n",
        "        if params['batch_norm']==True:\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "        # Dense layer\n",
        "        model.add(Dense(layer_neurons[i],\n",
        "                        kernel_initializer=params['kernel_initializer'],\n",
        "                        kernel_regularizer = params['kernel_regularizer'],\n",
        "                        activity_regularizer = params['activity_regularizer'],\n",
        "                        use_bias=True))\n",
        "        \n",
        "        # Activation function  \n",
        "        if params['activation']=='prelu':\n",
        "            model.add( PReLU(alpha_initializer = Constant(value=params['alpha_initializer']) ))\n",
        "        elif params['activation']=='elu':\n",
        "            model.add(ELU(alpha=0.5))\n",
        "        elif params['activation']=='leaky_relu':\n",
        "            model.add(LeakyReLU())\n",
        "        else:\n",
        "            model.add(Activation(params['activation']))\n",
        "\n",
        "        # Dropout layer\n",
        "        if(params['dropout']>0):\n",
        "            model.add(Dropout(params['dropout']/2))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1, kernel_initializer=params['kernel_initializer'], activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "    # Optimizer\n",
        "    opt = optimizers.Adam(\n",
        "                learning_rate=lr_normalizer(params['lr'],Adam),\n",
        "                beta_1=0.9,\n",
        "                beta_2=0.999,\n",
        "                epsilon=1e-7,\n",
        "                amsgrad=False)\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt ,metrics=['accuracy'])#,\n",
        "    \n",
        "    return model\n",
        "\n",
        "def tox21_talos(x, y, x_v, y_v, params):\n",
        "\n",
        "    # Create model\n",
        "    model = tox21_model(x,y,params)\n",
        "\n",
        "    print(\"_____________________________________________________________________\")\n",
        "    for key in params:\n",
        "        print(f\"{key:20}{params[key]}\")\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    # logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    es = EarlyStopping(monitor='val_loss', verbose=1, patience=25, restore_best_weights = True)\n",
        "    reduceLR=ReduceLROnPlateau(monitor='val_loss', \n",
        "                            factor=0.2, \n",
        "                            patience=10, \n",
        "                            verbose=1, \n",
        "                            min_delta=0, \n",
        "                            cooldown=0, min_lr=0)\n",
        "\n",
        "    history = model.fit(x, y, validation_data = (x_v, y_v),\n",
        "                        batch_size = params['batch_size'],\n",
        "                        epochs = params['epochs'],\n",
        "                        callbacks=[es,reduceLR], #,TensorBoard(logdir, histogram_freq=1)\n",
        "                        verbose=2)\n",
        "    \n",
        "    return history, model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo2bKRV6QfMM",
        "colab_type": "text"
      },
      "source": [
        "Hiperparametros\n",
        "\n",
        "Diccionario con los hiperparametros a evaluar. Debido a que la cantidad de hiperparametros es muy grande, se realizo una busqueda por partes para minimizar el tiempo de computo. Esta busqueda conistio en dejar fijos algunos hiperparametros y variar otros, siguiendo un orden:\n",
        "\n",
        "1. Funciones de activacion e inicializadores\n",
        "\n",
        "        Funciones de activacion: {Relu, Prelu, LeakyRelu, Helu, Tanh}\n",
        "\n",
        "        Inicializadores: {Random_uniform, Random_normal, He_uniform, He_normal, Glorot_normal}\n",
        "\n",
        "2. Neuronas, Hidden Layers, Shapes\n",
        "\n",
        "        Neuronas: {64, 256, 512, 1024}\n",
        "\n",
        "        Hidden Layers: {3,4,5}\n",
        "\n",
        "        Shapes: {Brick, Triangle, Funnel}\n",
        "\n",
        "3. Regularizacion, Dropout, Batch Normalization\n",
        "        \n",
        "        Regularizacion: {None, l1, l2}\n",
        "\n",
        "        Dropout: {0, 0.2, 0.4}\n",
        "\n",
        "        Batch Normalization: {True, False}\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y714J3nzs1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = {\n",
        "    'first_neuron': [512],                 # Tamaño de la primera capa\n",
        "    'dropout': [0,0.2,0.4],                    # Valor de dropout luego de la primera capa\n",
        "    'activation': ['tanh'],                # Función de activación\n",
        "    'alpha_initializer': [0.2],             # PRELU alpha\n",
        "    'batch_size': [256],#, 512],                    # Tamaño de batch\n",
        "    'epochs': [400],                        # Number of epochs\n",
        "    'batch_norm': [True,False],                   # Batch normalization layers\n",
        "    'hidden_layers':[5],                    # Number of hidde layers\n",
        "    'shapes':['brick'],                     # Shape of hidden layers\n",
        "    'optimizer': [Adam],                    # Optimizer\n",
        "    'kernel_regularizer':[None, 'l1,','l2'],            # Kernel (weights) regularization\n",
        "    #'bias_regularizer':[None],             # Bias (offsets) regularization\n",
        "    'activity_regularizer':[None],          # Activity (output) regularization\n",
        "    'kernel_initializer': ['random_normal'], # Kernel (weights) initializer\n",
        "    'lr': [0.1]                              # Learning rate\n",
        "}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrE3MuK2QjKm",
        "colab_type": "text"
      },
      "source": [
        "Talos Scan\n",
        "\n",
        "Se realiza el scan con cada grupo de hiperparametros y se guardan los resultados en distintos CSVs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoDAe1U1D4Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%reload_ext tensorboard\n",
        "\n",
        "scan = talos.Scan (x=X_train,\n",
        "                    y=y_train,\n",
        "                    model=tox21_talos,\n",
        "                    experiment_name='tox21_SCAN_nr_er_regularizacion',\n",
        "                    #fraction_limit=0.004,\n",
        "                    #round_limit = 200,\n",
        "                    random_method = 'uniform_mersenne' ,\n",
        "                    x_val=X_val,\n",
        "                    y_val=y_val,\n",
        "                    params=p,\n",
        "                    print_params=False,) \n",
        "\n",
        "#El output de esta funcion se guarda en un archivo csv que permite visualizar los resultados de las metricas para cada combinacion de HP.\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyo9XGhyQnup",
        "colab_type": "text"
      },
      "source": [
        "## Modelo con mejores hiperparametros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCiVyN2AQ1aw",
        "colab_type": "text"
      },
      "source": [
        "Definicion del modelo\n",
        "\n",
        "Se define el modelo de acuerdo con los hiperparametros que dieron mejor resultado, los cuales se definieron inspeccionando los CSVs creados en la seccion anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m7AqA05k3no",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "a0d7e799-3c68-4a74-e977-012dfc50c465"
      },
      "source": [
        "# define the model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(512, input_dim = 27, kernel_initializer='he_uniform', activation = 'tanh'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512,kernel_regularizer = 'l2', kernel_initializer='he_uniform', activation ='tanh'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(512,kernel_regularizer = 'l2',kernel_initializer='he_uniform', activation = 'tanh'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(512,kernel_regularizer = 'l2',kernel_initializer='he_uniform', activation = 'tanh'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(512,kernel_regularizer = 'l2',kernel_initializer='he_uniform', activation = 'tanh'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(1,kernel_initializer='he_uniform', activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 512)               14336     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,075,713\n",
            "Trainable params: 1,070,593\n",
            "Non-trainable params: 5,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1-V_CqFQ8UW",
        "colab_type": "text"
      },
      "source": [
        "Optimizador y compile\n",
        "\n",
        "Dado que las clases se encuentran desbalanceadas (88-12%), se decidio utilizar la metrica AUC, que es el area bajo la curva ROC. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p6uD5gdLsBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optimizers.Adam(\n",
        "                learning_rate=lr_normalizer(0.1,Adam),\n",
        "                beta_1=0.9,\n",
        "                beta_2=0.999,\n",
        "                epsilon=1e-7,\n",
        "                amsgrad=False)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer ,metrics=[AUC()])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SytlMh2Q_x-",
        "colab_type": "text"
      },
      "source": [
        "Callbacks\n",
        "\n",
        "Se utilizara Early Stopping para detener el entrenamiento cuando la \"val_loss\" deje de mejorar, guardandose los pesos del mejor modelo. Tambien se utilizara el callback ReduceLROnPlateau para disminuir el Learning Rate cuando la \"val_loss\" no mejore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA4J2b5SMHPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', verbose=1, patience=85, restore_best_weights = True)\n",
        "reduceLR=ReduceLROnPlateau(monitor='val_loss', \n",
        "                            factor=0.2, \n",
        "                            patience=10, \n",
        "                            verbose=1, \n",
        "                            min_delta=0, \n",
        "                            cooldown=0, min_lr=0)\n",
        "\n",
        "checkpoint_filepath = 'bestmodel.hdf5'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_auc',\n",
        "    mode='max')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5rBAmgQdj-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train.reshape(6927,1)\n",
        "y_val = y_val.reshape(770,1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBk3vR5jRB-6",
        "colab_type": "text"
      },
      "source": [
        "Entrenamiento\n",
        "\n",
        "Se entrena el modelo planteado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I67QxBbilZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b197175-aefe-49e9-c6ec-1a435f63d96b"
      },
      "source": [
        "hist = model.fit(X_train, y_train, batch_size=256, validation_data=(X_val, y_val), epochs=400, verbose=2, shuffle=True, callbacks=[es, reduceLR])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6927 samples, validate on 770 samples\n",
            "Epoch 1/400\n",
            " - 1s - loss: 40.9520 - auc_4: 0.5902 - val_loss: 39.8275 - val_auc_4: 0.6323\n",
            "Epoch 2/400\n",
            " - 0s - loss: 39.0129 - auc_4: 0.6527 - val_loss: 37.9825 - val_auc_4: 0.6635\n",
            "Epoch 3/400\n",
            " - 0s - loss: 37.1431 - auc_4: 0.6725 - val_loss: 36.1381 - val_auc_4: 0.6814\n",
            "Epoch 4/400\n",
            " - 0s - loss: 35.2975 - auc_4: 0.6889 - val_loss: 34.3225 - val_auc_4: 0.6967\n",
            "Epoch 5/400\n",
            " - 0s - loss: 33.5179 - auc_4: 0.7008 - val_loss: 32.5856 - val_auc_4: 0.7048\n",
            "Epoch 6/400\n",
            " - 0s - loss: 31.7955 - auc_4: 0.7067 - val_loss: 30.8948 - val_auc_4: 0.7104\n",
            "Epoch 7/400\n",
            " - 0s - loss: 30.1241 - auc_4: 0.7133 - val_loss: 29.2660 - val_auc_4: 0.7166\n",
            "Epoch 8/400\n",
            " - 0s - loss: 28.5317 - auc_4: 0.7186 - val_loss: 27.7092 - val_auc_4: 0.7212\n",
            "Epoch 9/400\n",
            " - 0s - loss: 27.0137 - auc_4: 0.7234 - val_loss: 26.2387 - val_auc_4: 0.7250\n",
            "Epoch 10/400\n",
            " - 0s - loss: 25.5593 - auc_4: 0.7270 - val_loss: 24.8144 - val_auc_4: 0.7290\n",
            "Epoch 11/400\n",
            " - 0s - loss: 24.1663 - auc_4: 0.7315 - val_loss: 23.4575 - val_auc_4: 0.7333\n",
            "Epoch 12/400\n",
            " - 0s - loss: 22.8477 - auc_4: 0.7349 - val_loss: 22.1768 - val_auc_4: 0.7362\n",
            "Epoch 13/400\n",
            " - 0s - loss: 21.5972 - auc_4: 0.7373 - val_loss: 20.9700 - val_auc_4: 0.7377\n",
            "Epoch 14/400\n",
            " - 0s - loss: 20.4126 - auc_4: 0.7384 - val_loss: 19.8098 - val_auc_4: 0.7393\n",
            "Epoch 15/400\n",
            " - 0s - loss: 19.3017 - auc_4: 0.7398 - val_loss: 18.7444 - val_auc_4: 0.7405\n",
            "Epoch 16/400\n",
            " - 0s - loss: 18.2391 - auc_4: 0.7416 - val_loss: 17.7047 - val_auc_4: 0.7421\n",
            "Epoch 17/400\n",
            " - 0s - loss: 17.2328 - auc_4: 0.7435 - val_loss: 16.7264 - val_auc_4: 0.7442\n",
            "Epoch 18/400\n",
            " - 0s - loss: 16.2802 - auc_4: 0.7448 - val_loss: 15.8037 - val_auc_4: 0.7454\n",
            "Epoch 19/400\n",
            " - 0s - loss: 15.3689 - auc_4: 0.7459 - val_loss: 14.9154 - val_auc_4: 0.7462\n",
            "Epoch 20/400\n",
            " - 0s - loss: 14.5018 - auc_4: 0.7473 - val_loss: 14.0733 - val_auc_4: 0.7473\n",
            "Epoch 21/400\n",
            " - 0s - loss: 13.6841 - auc_4: 0.7477 - val_loss: 13.2754 - val_auc_4: 0.7480\n",
            "Epoch 22/400\n",
            " - 0s - loss: 12.9020 - auc_4: 0.7484 - val_loss: 12.5217 - val_auc_4: 0.7491\n",
            "Epoch 23/400\n",
            " - 0s - loss: 12.1727 - auc_4: 0.7493 - val_loss: 11.8142 - val_auc_4: 0.7494\n",
            "Epoch 24/400\n",
            " - 0s - loss: 11.4735 - auc_4: 0.7499 - val_loss: 11.1426 - val_auc_4: 0.7502\n",
            "Epoch 25/400\n",
            " - 0s - loss: 10.8249 - auc_4: 0.7507 - val_loss: 10.5091 - val_auc_4: 0.7507\n",
            "Epoch 26/400\n",
            " - 0s - loss: 10.2182 - auc_4: 0.7509 - val_loss: 9.9070 - val_auc_4: 0.7512\n",
            "Epoch 27/400\n",
            " - 0s - loss: 9.6302 - auc_4: 0.7515 - val_loss: 9.3563 - val_auc_4: 0.7513\n",
            "Epoch 28/400\n",
            " - 0s - loss: 9.0755 - auc_4: 0.7518 - val_loss: 8.8523 - val_auc_4: 0.7523\n",
            "Epoch 29/400\n",
            " - 0s - loss: 8.5812 - auc_4: 0.7522 - val_loss: 8.3508 - val_auc_4: 0.7520\n",
            "Epoch 30/400\n",
            " - 0s - loss: 8.0853 - auc_4: 0.7522 - val_loss: 7.8511 - val_auc_4: 0.7522\n",
            "Epoch 31/400\n",
            " - 0s - loss: 7.6286 - auc_4: 0.7522 - val_loss: 7.4143 - val_auc_4: 0.7524\n",
            "Epoch 32/400\n",
            " - 0s - loss: 7.1948 - auc_4: 0.7526 - val_loss: 6.9901 - val_auc_4: 0.7528\n",
            "Epoch 33/400\n",
            " - 0s - loss: 6.7873 - auc_4: 0.7532 - val_loss: 6.6017 - val_auc_4: 0.7532\n",
            "Epoch 34/400\n",
            " - 0s - loss: 6.4009 - auc_4: 0.7535 - val_loss: 6.2260 - val_auc_4: 0.7537\n",
            "Epoch 35/400\n",
            " - 0s - loss: 6.0519 - auc_4: 0.7540 - val_loss: 5.8954 - val_auc_4: 0.7540\n",
            "Epoch 36/400\n",
            " - 0s - loss: 5.7267 - auc_4: 0.7540 - val_loss: 5.5572 - val_auc_4: 0.7537\n",
            "Epoch 37/400\n",
            " - 0s - loss: 5.3906 - auc_4: 0.7540 - val_loss: 5.2532 - val_auc_4: 0.7542\n",
            "Epoch 38/400\n",
            " - 0s - loss: 5.0871 - auc_4: 0.7547 - val_loss: 5.0022 - val_auc_4: 0.7548\n",
            "Epoch 39/400\n",
            " - 0s - loss: 4.8252 - auc_4: 0.7546 - val_loss: 4.7078 - val_auc_4: 0.7547\n",
            "Epoch 40/400\n",
            " - 0s - loss: 4.5726 - auc_4: 0.7547 - val_loss: 4.4410 - val_auc_4: 0.7546\n",
            "Epoch 41/400\n",
            " - 0s - loss: 4.3068 - auc_4: 0.7548 - val_loss: 4.2032 - val_auc_4: 0.7549\n",
            "Epoch 42/400\n",
            " - 0s - loss: 4.0761 - auc_4: 0.7548 - val_loss: 3.9794 - val_auc_4: 0.7551\n",
            "Epoch 43/400\n",
            " - 0s - loss: 3.8591 - auc_4: 0.7551 - val_loss: 3.7687 - val_auc_4: 0.7553\n",
            "Epoch 44/400\n",
            " - 0s - loss: 3.6527 - auc_4: 0.7554 - val_loss: 3.5752 - val_auc_4: 0.7554\n",
            "Epoch 45/400\n",
            " - 0s - loss: 3.4558 - auc_4: 0.7555 - val_loss: 3.3766 - val_auc_4: 0.7559\n",
            "Epoch 46/400\n",
            " - 0s - loss: 3.2625 - auc_4: 0.7563 - val_loss: 3.2216 - val_auc_4: 0.7564\n",
            "Epoch 47/400\n",
            " - 0s - loss: 3.0995 - auc_4: 0.7565 - val_loss: 3.0266 - val_auc_4: 0.7566\n",
            "Epoch 48/400\n",
            " - 0s - loss: 2.9248 - auc_4: 0.7569 - val_loss: 2.8691 - val_auc_4: 0.7572\n",
            "Epoch 49/400\n",
            " - 0s - loss: 2.7747 - auc_4: 0.7575 - val_loss: 2.7177 - val_auc_4: 0.7576\n",
            "Epoch 50/400\n",
            " - 0s - loss: 2.6291 - auc_4: 0.7579 - val_loss: 2.5964 - val_auc_4: 0.7580\n",
            "Epoch 51/400\n",
            " - 0s - loss: 2.4902 - auc_4: 0.7584 - val_loss: 2.4548 - val_auc_4: 0.7585\n",
            "Epoch 52/400\n",
            " - 0s - loss: 2.3762 - auc_4: 0.7585 - val_loss: 2.3329 - val_auc_4: 0.7586\n",
            "Epoch 53/400\n",
            " - 0s - loss: 2.2466 - auc_4: 0.7585 - val_loss: 2.2102 - val_auc_4: 0.7588\n",
            "Epoch 54/400\n",
            " - 0s - loss: 2.1302 - auc_4: 0.7589 - val_loss: 2.0905 - val_auc_4: 0.7590\n",
            "Epoch 55/400\n",
            " - 0s - loss: 2.0200 - auc_4: 0.7592 - val_loss: 1.9994 - val_auc_4: 0.7595\n",
            "Epoch 56/400\n",
            " - 0s - loss: 1.9292 - auc_4: 0.7597 - val_loss: 1.9104 - val_auc_4: 0.7596\n",
            "Epoch 57/400\n",
            " - 0s - loss: 1.8397 - auc_4: 0.7596 - val_loss: 1.8251 - val_auc_4: 0.7596\n",
            "Epoch 58/400\n",
            " - 0s - loss: 1.7515 - auc_4: 0.7595 - val_loss: 1.7262 - val_auc_4: 0.7596\n",
            "Epoch 59/400\n",
            " - 0s - loss: 1.6572 - auc_4: 0.7599 - val_loss: 1.6448 - val_auc_4: 0.7600\n",
            "Epoch 60/400\n",
            " - 0s - loss: 1.5750 - auc_4: 0.7601 - val_loss: 1.5846 - val_auc_4: 0.7604\n",
            "Epoch 61/400\n",
            " - 0s - loss: 1.5031 - auc_4: 0.7605 - val_loss: 1.4943 - val_auc_4: 0.7606\n",
            "Epoch 62/400\n",
            " - 0s - loss: 1.4345 - auc_4: 0.7608 - val_loss: 1.4381 - val_auc_4: 0.7610\n",
            "Epoch 63/400\n",
            " - 0s - loss: 1.3734 - auc_4: 0.7610 - val_loss: 1.3781 - val_auc_4: 0.7612\n",
            "Epoch 64/400\n",
            " - 0s - loss: 1.3329 - auc_4: 0.7612 - val_loss: 1.3337 - val_auc_4: 0.7611\n",
            "Epoch 65/400\n",
            " - 0s - loss: 1.2618 - auc_4: 0.7612 - val_loss: 1.2551 - val_auc_4: 0.7612\n",
            "Epoch 66/400\n",
            " - 0s - loss: 1.1977 - auc_4: 0.7613 - val_loss: 1.2053 - val_auc_4: 0.7615\n",
            "Epoch 67/400\n",
            " - 0s - loss: 1.1519 - auc_4: 0.7616 - val_loss: 1.1730 - val_auc_4: 0.7617\n",
            "Epoch 68/400\n",
            " - 0s - loss: 1.1194 - auc_4: 0.7617 - val_loss: 1.1059 - val_auc_4: 0.7617\n",
            "Epoch 69/400\n",
            " - 0s - loss: 1.0599 - auc_4: 0.7618 - val_loss: 1.0710 - val_auc_4: 0.7619\n",
            "Epoch 70/400\n",
            " - 0s - loss: 1.0199 - auc_4: 0.7620 - val_loss: 1.0448 - val_auc_4: 0.7620\n",
            "Epoch 71/400\n",
            " - 0s - loss: 0.9850 - auc_4: 0.7621 - val_loss: 0.9808 - val_auc_4: 0.7622\n",
            "Epoch 72/400\n",
            " - 0s - loss: 0.9555 - auc_4: 0.7622 - val_loss: 0.9559 - val_auc_4: 0.7623\n",
            "Epoch 73/400\n",
            " - 0s - loss: 0.9180 - auc_4: 0.7624 - val_loss: 0.9457 - val_auc_4: 0.7623\n",
            "Epoch 74/400\n",
            " - 0s - loss: 0.8986 - auc_4: 0.7621 - val_loss: 0.8964 - val_auc_4: 0.7621\n",
            "Epoch 75/400\n",
            " - 0s - loss: 0.8520 - auc_4: 0.7622 - val_loss: 0.8580 - val_auc_4: 0.7622\n",
            "Epoch 76/400\n",
            " - 0s - loss: 0.8143 - auc_4: 0.7625 - val_loss: 0.8322 - val_auc_4: 0.7625\n",
            "Epoch 77/400\n",
            " - 0s - loss: 0.7859 - auc_4: 0.7627 - val_loss: 0.8010 - val_auc_4: 0.7628\n",
            "Epoch 78/400\n",
            " - 0s - loss: 0.7645 - auc_4: 0.7631 - val_loss: 0.7748 - val_auc_4: 0.7630\n",
            "Epoch 79/400\n",
            " - 0s - loss: 0.7413 - auc_4: 0.7632 - val_loss: 0.7519 - val_auc_4: 0.7633\n",
            "Epoch 80/400\n",
            " - 0s - loss: 0.7091 - auc_4: 0.7635 - val_loss: 0.7405 - val_auc_4: 0.7637\n",
            "Epoch 81/400\n",
            " - 0s - loss: 0.6908 - auc_4: 0.7639 - val_loss: 0.7170 - val_auc_4: 0.7640\n",
            "Epoch 82/400\n",
            " - 0s - loss: 0.6764 - auc_4: 0.7641 - val_loss: 0.6873 - val_auc_4: 0.7642\n",
            "Epoch 83/400\n",
            " - 0s - loss: 0.6572 - auc_4: 0.7643 - val_loss: 0.6913 - val_auc_4: 0.7644\n",
            "Epoch 84/400\n",
            " - 0s - loss: 0.6486 - auc_4: 0.7645 - val_loss: 0.6557 - val_auc_4: 0.7645\n",
            "Epoch 85/400\n",
            " - 0s - loss: 0.6321 - auc_4: 0.7645 - val_loss: 0.6563 - val_auc_4: 0.7645\n",
            "Epoch 86/400\n",
            " - 0s - loss: 0.6162 - auc_4: 0.7645 - val_loss: 0.6196 - val_auc_4: 0.7645\n",
            "Epoch 87/400\n",
            " - 0s - loss: 0.5860 - auc_4: 0.7647 - val_loss: 0.6151 - val_auc_4: 0.7648\n",
            "Epoch 88/400\n",
            " - 0s - loss: 0.5783 - auc_4: 0.7649 - val_loss: 0.6009 - val_auc_4: 0.7649\n",
            "Epoch 89/400\n",
            " - 0s - loss: 0.5616 - auc_4: 0.7651 - val_loss: 0.5957 - val_auc_4: 0.7651\n",
            "Epoch 90/400\n",
            " - 0s - loss: 0.5687 - auc_4: 0.7651 - val_loss: 0.5700 - val_auc_4: 0.7650\n",
            "Epoch 91/400\n",
            " - 0s - loss: 0.5528 - auc_4: 0.7650 - val_loss: 0.5971 - val_auc_4: 0.7650\n",
            "Epoch 92/400\n",
            " - 0s - loss: 0.5355 - auc_4: 0.7650 - val_loss: 0.5539 - val_auc_4: 0.7651\n",
            "Epoch 93/400\n",
            " - 0s - loss: 0.5224 - auc_4: 0.7652 - val_loss: 0.5440 - val_auc_4: 0.7652\n",
            "Epoch 94/400\n",
            " - 0s - loss: 0.5026 - auc_4: 0.7654 - val_loss: 0.5457 - val_auc_4: 0.7655\n",
            "Epoch 95/400\n",
            " - 0s - loss: 0.4986 - auc_4: 0.7655 - val_loss: 0.5085 - val_auc_4: 0.7656\n",
            "Epoch 96/400\n",
            " - 0s - loss: 0.4833 - auc_4: 0.7658 - val_loss: 0.4996 - val_auc_4: 0.7659\n",
            "Epoch 97/400\n",
            " - 0s - loss: 0.4803 - auc_4: 0.7660 - val_loss: 0.5053 - val_auc_4: 0.7660\n",
            "Epoch 98/400\n",
            " - 0s - loss: 0.4696 - auc_4: 0.7662 - val_loss: 0.5055 - val_auc_4: 0.7663\n",
            "Epoch 99/400\n",
            " - 0s - loss: 0.4690 - auc_4: 0.7663 - val_loss: 0.4924 - val_auc_4: 0.7663\n",
            "Epoch 100/400\n",
            " - 0s - loss: 0.4664 - auc_4: 0.7663 - val_loss: 0.4787 - val_auc_4: 0.7663\n",
            "Epoch 101/400\n",
            " - 0s - loss: 0.4549 - auc_4: 0.7664 - val_loss: 0.4677 - val_auc_4: 0.7665\n",
            "Epoch 102/400\n",
            " - 0s - loss: 0.4442 - auc_4: 0.7666 - val_loss: 0.4627 - val_auc_4: 0.7667\n",
            "Epoch 103/400\n",
            " - 0s - loss: 0.4361 - auc_4: 0.7668 - val_loss: 0.4588 - val_auc_4: 0.7669\n",
            "Epoch 104/400\n",
            " - 0s - loss: 0.4401 - auc_4: 0.7670 - val_loss: 0.4598 - val_auc_4: 0.7669\n",
            "Epoch 105/400\n",
            " - 0s - loss: 0.4273 - auc_4: 0.7670 - val_loss: 0.4444 - val_auc_4: 0.7670\n",
            "Epoch 106/400\n",
            " - 0s - loss: 0.4274 - auc_4: 0.7670 - val_loss: 0.4482 - val_auc_4: 0.7672\n",
            "Epoch 107/400\n",
            " - 0s - loss: 0.4229 - auc_4: 0.7672 - val_loss: 0.4341 - val_auc_4: 0.7673\n",
            "Epoch 108/400\n",
            " - 0s - loss: 0.4149 - auc_4: 0.7673 - val_loss: 0.4313 - val_auc_4: 0.7674\n",
            "Epoch 109/400\n",
            " - 0s - loss: 0.4142 - auc_4: 0.7675 - val_loss: 0.4308 - val_auc_4: 0.7675\n",
            "Epoch 110/400\n",
            " - 0s - loss: 0.4047 - auc_4: 0.7675 - val_loss: 0.4235 - val_auc_4: 0.7676\n",
            "Epoch 111/400\n",
            " - 0s - loss: 0.3965 - auc_4: 0.7677 - val_loss: 0.4278 - val_auc_4: 0.7678\n",
            "Epoch 112/400\n",
            " - 0s - loss: 0.4075 - auc_4: 0.7677 - val_loss: 0.4093 - val_auc_4: 0.7678\n",
            "Epoch 113/400\n",
            " - 0s - loss: 0.3910 - auc_4: 0.7679 - val_loss: 0.4169 - val_auc_4: 0.7679\n",
            "Epoch 114/400\n",
            " - 0s - loss: 0.3898 - auc_4: 0.7680 - val_loss: 0.4235 - val_auc_4: 0.7680\n",
            "Epoch 115/400\n",
            " - 0s - loss: 0.3905 - auc_4: 0.7680 - val_loss: 0.4070 - val_auc_4: 0.7681\n",
            "Epoch 116/400\n",
            " - 0s - loss: 0.3890 - auc_4: 0.7681 - val_loss: 0.3997 - val_auc_4: 0.7681\n",
            "Epoch 117/400\n",
            " - 0s - loss: 0.3778 - auc_4: 0.7682 - val_loss: 0.4119 - val_auc_4: 0.7682\n",
            "Epoch 118/400\n",
            " - 0s - loss: 0.3834 - auc_4: 0.7682 - val_loss: 0.4394 - val_auc_4: 0.7683\n",
            "Epoch 119/400\n",
            " - 0s - loss: 0.3755 - auc_4: 0.7683 - val_loss: 0.3923 - val_auc_4: 0.7684\n",
            "Epoch 120/400\n",
            " - 0s - loss: 0.3660 - auc_4: 0.7685 - val_loss: 0.3852 - val_auc_4: 0.7686\n",
            "Epoch 121/400\n",
            " - 0s - loss: 0.3713 - auc_4: 0.7686 - val_loss: 0.3905 - val_auc_4: 0.7687\n",
            "Epoch 122/400\n",
            " - 0s - loss: 0.3705 - auc_4: 0.7687 - val_loss: 0.3819 - val_auc_4: 0.7688\n",
            "Epoch 123/400\n",
            " - 0s - loss: 0.3615 - auc_4: 0.7689 - val_loss: 0.3966 - val_auc_4: 0.7689\n",
            "Epoch 124/400\n",
            " - 0s - loss: 0.3597 - auc_4: 0.7690 - val_loss: 0.3879 - val_auc_4: 0.7691\n",
            "Epoch 125/400\n",
            " - 0s - loss: 0.3506 - auc_4: 0.7692 - val_loss: 0.3888 - val_auc_4: 0.7693\n",
            "Epoch 126/400\n",
            " - 0s - loss: 0.3690 - auc_4: 0.7693 - val_loss: 0.3953 - val_auc_4: 0.7693\n",
            "Epoch 127/400\n",
            " - 0s - loss: 0.3667 - auc_4: 0.7693 - val_loss: 0.3931 - val_auc_4: 0.7693\n",
            "Epoch 128/400\n",
            " - 0s - loss: 0.3555 - auc_4: 0.7693 - val_loss: 0.3727 - val_auc_4: 0.7694\n",
            "Epoch 129/400\n",
            " - 0s - loss: 0.3481 - auc_4: 0.7695 - val_loss: 0.3769 - val_auc_4: 0.7695\n",
            "Epoch 130/400\n",
            " - 0s - loss: 0.3478 - auc_4: 0.7696 - val_loss: 0.3668 - val_auc_4: 0.7697\n",
            "Epoch 131/400\n",
            " - 0s - loss: 0.3525 - auc_4: 0.7697 - val_loss: 0.3671 - val_auc_4: 0.7698\n",
            "Epoch 132/400\n",
            " - 0s - loss: 0.3438 - auc_4: 0.7698 - val_loss: 0.3711 - val_auc_4: 0.7699\n",
            "Epoch 133/400\n",
            " - 0s - loss: 0.3433 - auc_4: 0.7700 - val_loss: 0.3760 - val_auc_4: 0.7701\n",
            "Epoch 134/400\n",
            " - 0s - loss: 0.3370 - auc_4: 0.7702 - val_loss: 0.3894 - val_auc_4: 0.7702\n",
            "Epoch 135/400\n",
            " - 0s - loss: 0.3407 - auc_4: 0.7703 - val_loss: 0.3929 - val_auc_4: 0.7703\n",
            "Epoch 136/400\n",
            " - 0s - loss: 0.3437 - auc_4: 0.7703 - val_loss: 0.3679 - val_auc_4: 0.7704\n",
            "Epoch 137/400\n",
            " - 0s - loss: 0.3438 - auc_4: 0.7704 - val_loss: 0.3578 - val_auc_4: 0.7704\n",
            "Epoch 138/400\n",
            " - 0s - loss: 0.3352 - auc_4: 0.7705 - val_loss: 0.3618 - val_auc_4: 0.7706\n",
            "Epoch 139/400\n",
            " - 0s - loss: 0.3388 - auc_4: 0.7706 - val_loss: 0.3506 - val_auc_4: 0.7706\n",
            "Epoch 140/400\n",
            " - 0s - loss: 0.3404 - auc_4: 0.7706 - val_loss: 0.3595 - val_auc_4: 0.7707\n",
            "Epoch 141/400\n",
            " - 0s - loss: 0.3282 - auc_4: 0.7707 - val_loss: 0.3488 - val_auc_4: 0.7708\n",
            "Epoch 142/400\n",
            " - 0s - loss: 0.3338 - auc_4: 0.7709 - val_loss: 0.4475 - val_auc_4: 0.7709\n",
            "Epoch 143/400\n",
            " - 0s - loss: 0.3356 - auc_4: 0.7710 - val_loss: 0.3531 - val_auc_4: 0.7711\n",
            "Epoch 144/400\n",
            " - 0s - loss: 0.3324 - auc_4: 0.7711 - val_loss: 0.3618 - val_auc_4: 0.7711\n",
            "Epoch 145/400\n",
            " - 0s - loss: 0.3276 - auc_4: 0.7712 - val_loss: 0.3642 - val_auc_4: 0.7713\n",
            "Epoch 146/400\n",
            " - 0s - loss: 0.3270 - auc_4: 0.7714 - val_loss: 0.3580 - val_auc_4: 0.7715\n",
            "Epoch 147/400\n",
            " - 0s - loss: 0.3263 - auc_4: 0.7715 - val_loss: 0.3590 - val_auc_4: 0.7716\n",
            "Epoch 148/400\n",
            " - 0s - loss: 0.3340 - auc_4: 0.7717 - val_loss: 0.3662 - val_auc_4: 0.7717\n",
            "Epoch 149/400\n",
            " - 0s - loss: 0.3353 - auc_4: 0.7717 - val_loss: 0.5730 - val_auc_4: 0.7717\n",
            "Epoch 150/400\n",
            " - 0s - loss: 0.3396 - auc_4: 0.7717 - val_loss: 0.3506 - val_auc_4: 0.7717\n",
            "Epoch 151/400\n",
            " - 0s - loss: 0.3199 - auc_4: 0.7718 - val_loss: 0.3529 - val_auc_4: 0.7719\n",
            "\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "Epoch 152/400\n",
            " - 0s - loss: 0.3168 - auc_4: 0.7720 - val_loss: 0.3444 - val_auc_4: 0.7721\n",
            "Epoch 153/400\n",
            " - 0s - loss: 0.3143 - auc_4: 0.7722 - val_loss: 0.3403 - val_auc_4: 0.7723\n",
            "Epoch 154/400\n",
            " - 0s - loss: 0.3111 - auc_4: 0.7725 - val_loss: 0.3443 - val_auc_4: 0.7726\n",
            "Epoch 155/400\n",
            " - 0s - loss: 0.3102 - auc_4: 0.7727 - val_loss: 0.3558 - val_auc_4: 0.7728\n",
            "Epoch 156/400\n",
            " - 0s - loss: 0.3110 - auc_4: 0.7730 - val_loss: 0.3445 - val_auc_4: 0.7731\n",
            "Epoch 157/400\n",
            " - 0s - loss: 0.3120 - auc_4: 0.7732 - val_loss: 0.3551 - val_auc_4: 0.7733\n",
            "Epoch 158/400\n",
            " - 0s - loss: 0.3094 - auc_4: 0.7734 - val_loss: 0.3451 - val_auc_4: 0.7735\n",
            "Epoch 159/400\n",
            " - 0s - loss: 0.3092 - auc_4: 0.7737 - val_loss: 0.3383 - val_auc_4: 0.7738\n",
            "Epoch 160/400\n",
            " - 0s - loss: 0.3096 - auc_4: 0.7739 - val_loss: 0.3355 - val_auc_4: 0.7740\n",
            "Epoch 161/400\n",
            " - 0s - loss: 0.3068 - auc_4: 0.7741 - val_loss: 0.3361 - val_auc_4: 0.7743\n",
            "Epoch 162/400\n",
            " - 0s - loss: 0.3070 - auc_4: 0.7744 - val_loss: 0.3417 - val_auc_4: 0.7745\n",
            "Epoch 163/400\n",
            " - 0s - loss: 0.3039 - auc_4: 0.7747 - val_loss: 0.3426 - val_auc_4: 0.7748\n",
            "Epoch 164/400\n",
            " - 0s - loss: 0.3061 - auc_4: 0.7749 - val_loss: 0.3469 - val_auc_4: 0.7749\n",
            "Epoch 165/400\n",
            " - 0s - loss: 0.3044 - auc_4: 0.7751 - val_loss: 0.3417 - val_auc_4: 0.7752\n",
            "Epoch 166/400\n",
            " - 0s - loss: 0.3075 - auc_4: 0.7753 - val_loss: 0.3518 - val_auc_4: 0.7754\n",
            "Epoch 167/400\n",
            " - 0s - loss: 0.3048 - auc_4: 0.7755 - val_loss: 0.3350 - val_auc_4: 0.7756\n",
            "Epoch 168/400\n",
            " - 0s - loss: 0.3046 - auc_4: 0.7757 - val_loss: 0.3381 - val_auc_4: 0.7758\n",
            "Epoch 169/400\n",
            " - 0s - loss: 0.3049 - auc_4: 0.7760 - val_loss: 0.3372 - val_auc_4: 0.7761\n",
            "Epoch 170/400\n",
            " - 0s - loss: 0.3044 - auc_4: 0.7762 - val_loss: 0.3498 - val_auc_4: 0.7763\n",
            "Epoch 171/400\n",
            " - 0s - loss: 0.3023 - auc_4: 0.7764 - val_loss: 0.3315 - val_auc_4: 0.7765\n",
            "Epoch 172/400\n",
            " - 0s - loss: 0.3034 - auc_4: 0.7767 - val_loss: 0.3360 - val_auc_4: 0.7768\n",
            "Epoch 173/400\n",
            " - 0s - loss: 0.3021 - auc_4: 0.7769 - val_loss: 0.3310 - val_auc_4: 0.7770\n",
            "Epoch 174/400\n",
            " - 0s - loss: 0.3004 - auc_4: 0.7771 - val_loss: 0.3318 - val_auc_4: 0.7772\n",
            "Epoch 175/400\n",
            " - 0s - loss: 0.3010 - auc_4: 0.7773 - val_loss: 0.3328 - val_auc_4: 0.7775\n",
            "Epoch 176/400\n",
            " - 0s - loss: 0.3015 - auc_4: 0.7776 - val_loss: 0.3388 - val_auc_4: 0.7777\n",
            "Epoch 177/400\n",
            " - 0s - loss: 0.2999 - auc_4: 0.7778 - val_loss: 0.3314 - val_auc_4: 0.7779\n",
            "Epoch 178/400\n",
            " - 0s - loss: 0.2999 - auc_4: 0.7781 - val_loss: 0.3310 - val_auc_4: 0.7782\n",
            "Epoch 179/400\n",
            " - 0s - loss: 0.3029 - auc_4: 0.7783 - val_loss: 0.3320 - val_auc_4: 0.7784\n",
            "Epoch 180/400\n",
            " - 0s - loss: 0.2981 - auc_4: 0.7785 - val_loss: 0.3284 - val_auc_4: 0.7786\n",
            "Epoch 181/400\n",
            " - 0s - loss: 0.2996 - auc_4: 0.7787 - val_loss: 0.3342 - val_auc_4: 0.7788\n",
            "Epoch 182/400\n",
            " - 0s - loss: 0.2987 - auc_4: 0.7789 - val_loss: 0.3398 - val_auc_4: 0.7790\n",
            "Epoch 183/400\n",
            " - 0s - loss: 0.2991 - auc_4: 0.7792 - val_loss: 0.3339 - val_auc_4: 0.7792\n",
            "Epoch 184/400\n",
            " - 0s - loss: 0.2954 - auc_4: 0.7794 - val_loss: 0.3353 - val_auc_4: 0.7795\n",
            "Epoch 185/400\n",
            " - 0s - loss: 0.2993 - auc_4: 0.7796 - val_loss: 0.3302 - val_auc_4: 0.7797\n",
            "Epoch 186/400\n",
            " - 0s - loss: 0.2975 - auc_4: 0.7798 - val_loss: 0.3321 - val_auc_4: 0.7799\n",
            "Epoch 187/400\n",
            " - 0s - loss: 0.3000 - auc_4: 0.7800 - val_loss: 0.3325 - val_auc_4: 0.7801\n",
            "Epoch 188/400\n",
            " - 0s - loss: 0.3008 - auc_4: 0.7802 - val_loss: 0.3302 - val_auc_4: 0.7803\n",
            "Epoch 189/400\n",
            " - 0s - loss: 0.2936 - auc_4: 0.7804 - val_loss: 0.3372 - val_auc_4: 0.7806\n",
            "Epoch 190/400\n",
            " - 0s - loss: 0.2934 - auc_4: 0.7807 - val_loss: 0.3348 - val_auc_4: 0.7808\n",
            "\n",
            "Epoch 00190: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "Epoch 191/400\n",
            " - 0s - loss: 0.2931 - auc_4: 0.7809 - val_loss: 0.3300 - val_auc_4: 0.7810\n",
            "Epoch 192/400\n",
            " - 0s - loss: 0.2926 - auc_4: 0.7811 - val_loss: 0.3267 - val_auc_4: 0.7812\n",
            "Epoch 193/400\n",
            " - 0s - loss: 0.2907 - auc_4: 0.7814 - val_loss: 0.3264 - val_auc_4: 0.7815\n",
            "Epoch 194/400\n",
            " - 0s - loss: 0.2911 - auc_4: 0.7816 - val_loss: 0.3258 - val_auc_4: 0.7817\n",
            "Epoch 195/400\n",
            " - 0s - loss: 0.2891 - auc_4: 0.7819 - val_loss: 0.3289 - val_auc_4: 0.7820\n",
            "Epoch 196/400\n",
            " - 0s - loss: 0.2887 - auc_4: 0.7821 - val_loss: 0.3266 - val_auc_4: 0.7822\n",
            "Epoch 197/400\n",
            " - 0s - loss: 0.2903 - auc_4: 0.7824 - val_loss: 0.3265 - val_auc_4: 0.7825\n",
            "Epoch 198/400\n",
            " - 0s - loss: 0.2900 - auc_4: 0.7826 - val_loss: 0.3263 - val_auc_4: 0.7827\n",
            "Epoch 199/400\n",
            " - 0s - loss: 0.2897 - auc_4: 0.7828 - val_loss: 0.3308 - val_auc_4: 0.7829\n",
            "Epoch 200/400\n",
            " - 0s - loss: 0.2894 - auc_4: 0.7831 - val_loss: 0.3308 - val_auc_4: 0.7832\n",
            "Epoch 201/400\n",
            " - 0s - loss: 0.2904 - auc_4: 0.7833 - val_loss: 0.3288 - val_auc_4: 0.7834\n",
            "Epoch 202/400\n",
            " - 0s - loss: 0.2889 - auc_4: 0.7835 - val_loss: 0.3275 - val_auc_4: 0.7836\n",
            "Epoch 203/400\n",
            " - 0s - loss: 0.2886 - auc_4: 0.7838 - val_loss: 0.3258 - val_auc_4: 0.7839\n",
            "Epoch 204/400\n",
            " - 0s - loss: 0.2951 - auc_4: 0.7840 - val_loss: 0.3249 - val_auc_4: 0.7841\n",
            "Epoch 205/400\n",
            " - 0s - loss: 0.2911 - auc_4: 0.7842 - val_loss: 0.3258 - val_auc_4: 0.7843\n",
            "Epoch 206/400\n",
            " - 0s - loss: 0.2896 - auc_4: 0.7844 - val_loss: 0.3265 - val_auc_4: 0.7845\n",
            "Epoch 207/400\n",
            " - 0s - loss: 0.2889 - auc_4: 0.7846 - val_loss: 0.3257 - val_auc_4: 0.7847\n",
            "Epoch 208/400\n",
            " - 0s - loss: 0.2877 - auc_4: 0.7848 - val_loss: 0.3233 - val_auc_4: 0.7849\n",
            "Epoch 209/400\n",
            " - 0s - loss: 0.2904 - auc_4: 0.7850 - val_loss: 0.3247 - val_auc_4: 0.7851\n",
            "Epoch 210/400\n",
            " - 0s - loss: 0.2894 - auc_4: 0.7852 - val_loss: 0.3233 - val_auc_4: 0.7853\n",
            "Epoch 211/400\n",
            " - 0s - loss: 0.2885 - auc_4: 0.7854 - val_loss: 0.3247 - val_auc_4: 0.7855\n",
            "Epoch 212/400\n",
            " - 0s - loss: 0.2885 - auc_4: 0.7857 - val_loss: 0.3283 - val_auc_4: 0.7857\n",
            "Epoch 213/400\n",
            " - 0s - loss: 0.2915 - auc_4: 0.7858 - val_loss: 0.3264 - val_auc_4: 0.7859\n",
            "Epoch 214/400\n",
            " - 0s - loss: 0.2897 - auc_4: 0.7860 - val_loss: 0.3255 - val_auc_4: 0.7861\n",
            "Epoch 215/400\n",
            " - 0s - loss: 0.2876 - auc_4: 0.7862 - val_loss: 0.3240 - val_auc_4: 0.7863\n",
            "Epoch 216/400\n",
            " - 0s - loss: 0.2879 - auc_4: 0.7864 - val_loss: 0.3228 - val_auc_4: 0.7865\n",
            "Epoch 217/400\n",
            " - 0s - loss: 0.2860 - auc_4: 0.7867 - val_loss: 0.3241 - val_auc_4: 0.7868\n",
            "Epoch 218/400\n",
            " - 0s - loss: 0.2893 - auc_4: 0.7869 - val_loss: 0.3221 - val_auc_4: 0.7870\n",
            "Epoch 219/400\n",
            " - 0s - loss: 0.2878 - auc_4: 0.7871 - val_loss: 0.3230 - val_auc_4: 0.7872\n",
            "Epoch 220/400\n",
            " - 0s - loss: 0.2879 - auc_4: 0.7873 - val_loss: 0.3257 - val_auc_4: 0.7874\n",
            "Epoch 221/400\n",
            " - 0s - loss: 0.2838 - auc_4: 0.7875 - val_loss: 0.3243 - val_auc_4: 0.7876\n",
            "Epoch 222/400\n",
            " - 0s - loss: 0.2899 - auc_4: 0.7877 - val_loss: 0.3252 - val_auc_4: 0.7878\n",
            "Epoch 223/400\n",
            " - 0s - loss: 0.2879 - auc_4: 0.7879 - val_loss: 0.3251 - val_auc_4: 0.7880\n",
            "Epoch 224/400\n",
            " - 0s - loss: 0.2878 - auc_4: 0.7881 - val_loss: 0.3235 - val_auc_4: 0.7882\n",
            "Epoch 225/400\n",
            " - 0s - loss: 0.2879 - auc_4: 0.7883 - val_loss: 0.3234 - val_auc_4: 0.7884\n",
            "Epoch 226/400\n",
            " - 0s - loss: 0.2883 - auc_4: 0.7885 - val_loss: 0.3241 - val_auc_4: 0.7885\n",
            "Epoch 227/400\n",
            " - 0s - loss: 0.2873 - auc_4: 0.7886 - val_loss: 0.3223 - val_auc_4: 0.7887\n",
            "Epoch 228/400\n",
            " - 0s - loss: 0.2902 - auc_4: 0.7888 - val_loss: 0.3256 - val_auc_4: 0.7889\n",
            "\n",
            "Epoch 00228: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
            "Epoch 229/400\n",
            " - 0s - loss: 0.2855 - auc_4: 0.7890 - val_loss: 0.3245 - val_auc_4: 0.7891\n",
            "Epoch 230/400\n",
            " - 0s - loss: 0.2860 - auc_4: 0.7892 - val_loss: 0.3237 - val_auc_4: 0.7893\n",
            "Epoch 231/400\n",
            " - 0s - loss: 0.2878 - auc_4: 0.7894 - val_loss: 0.3236 - val_auc_4: 0.7895\n",
            "Epoch 232/400\n",
            " - 0s - loss: 0.2856 - auc_4: 0.7896 - val_loss: 0.3230 - val_auc_4: 0.7897\n",
            "Epoch 233/400\n",
            " - 0s - loss: 0.2862 - auc_4: 0.7898 - val_loss: 0.3233 - val_auc_4: 0.7899\n",
            "Epoch 234/400\n",
            " - 0s - loss: 0.2847 - auc_4: 0.7900 - val_loss: 0.3239 - val_auc_4: 0.7901\n",
            "Epoch 235/400\n",
            " - 0s - loss: 0.2851 - auc_4: 0.7902 - val_loss: 0.3232 - val_auc_4: 0.7902\n",
            "Epoch 236/400\n",
            " - 0s - loss: 0.2848 - auc_4: 0.7904 - val_loss: 0.3235 - val_auc_4: 0.7904\n",
            "Epoch 237/400\n",
            " - 0s - loss: 0.2881 - auc_4: 0.7905 - val_loss: 0.3234 - val_auc_4: 0.7906\n",
            "Epoch 238/400\n",
            " - 0s - loss: 0.2865 - auc_4: 0.7907 - val_loss: 0.3239 - val_auc_4: 0.7908\n",
            "\n",
            "Epoch 00238: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
            "Epoch 239/400\n",
            " - 0s - loss: 0.2843 - auc_4: 0.7909 - val_loss: 0.3239 - val_auc_4: 0.7910\n",
            "Epoch 240/400\n",
            " - 0s - loss: 0.2853 - auc_4: 0.7911 - val_loss: 0.3240 - val_auc_4: 0.7912\n",
            "Epoch 241/400\n",
            " - 0s - loss: 0.2857 - auc_4: 0.7913 - val_loss: 0.3239 - val_auc_4: 0.7914\n",
            "Epoch 242/400\n",
            " - 0s - loss: 0.2852 - auc_4: 0.7915 - val_loss: 0.3239 - val_auc_4: 0.7915\n",
            "Epoch 243/400\n",
            " - 0s - loss: 0.2870 - auc_4: 0.7917 - val_loss: 0.3239 - val_auc_4: 0.7917\n",
            "Epoch 244/400\n",
            " - 0s - loss: 0.2858 - auc_4: 0.7918 - val_loss: 0.3241 - val_auc_4: 0.7919\n",
            "Epoch 245/400\n",
            " - 0s - loss: 0.2844 - auc_4: 0.7920 - val_loss: 0.3243 - val_auc_4: 0.7921\n",
            "Epoch 246/400\n",
            " - 0s - loss: 0.2852 - auc_4: 0.7922 - val_loss: 0.3243 - val_auc_4: 0.7923\n",
            "Epoch 247/400\n",
            " - 0s - loss: 0.2850 - auc_4: 0.7923 - val_loss: 0.3242 - val_auc_4: 0.7924\n",
            "Epoch 248/400\n",
            " - 0s - loss: 0.2860 - auc_4: 0.7925 - val_loss: 0.3242 - val_auc_4: 0.7926\n",
            "\n",
            "Epoch 00248: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
            "Epoch 249/400\n",
            " - 0s - loss: 0.2901 - auc_4: 0.7927 - val_loss: 0.3240 - val_auc_4: 0.7927\n",
            "Epoch 250/400\n",
            " - 0s - loss: 0.2840 - auc_4: 0.7928 - val_loss: 0.3241 - val_auc_4: 0.7929\n",
            "Epoch 251/400\n",
            " - 0s - loss: 0.2877 - auc_4: 0.7930 - val_loss: 0.3240 - val_auc_4: 0.7931\n",
            "Epoch 252/400\n",
            " - 0s - loss: 0.2848 - auc_4: 0.7931 - val_loss: 0.3239 - val_auc_4: 0.7932\n",
            "Epoch 253/400\n",
            " - 0s - loss: 0.2840 - auc_4: 0.7933 - val_loss: 0.3238 - val_auc_4: 0.7934\n",
            "Epoch 254/400\n",
            " - 0s - loss: 0.2857 - auc_4: 0.7935 - val_loss: 0.3240 - val_auc_4: 0.7935\n",
            "Epoch 255/400\n",
            " - 0s - loss: 0.2908 - auc_4: 0.7936 - val_loss: 0.3239 - val_auc_4: 0.7937\n",
            "Epoch 256/400\n",
            " - 0s - loss: 0.2835 - auc_4: 0.7938 - val_loss: 0.3240 - val_auc_4: 0.7939\n",
            "Epoch 257/400\n",
            " - 0s - loss: 0.2882 - auc_4: 0.7939 - val_loss: 0.3240 - val_auc_4: 0.7940\n",
            "Epoch 258/400\n",
            " - 0s - loss: 0.2873 - auc_4: 0.7941 - val_loss: 0.3241 - val_auc_4: 0.7942\n",
            "\n",
            "Epoch 00258: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
            "Epoch 259/400\n",
            " - 0s - loss: 0.2856 - auc_4: 0.7942 - val_loss: 0.3240 - val_auc_4: 0.7943\n",
            "Epoch 260/400\n",
            " - 0s - loss: 0.2855 - auc_4: 0.7944 - val_loss: 0.3240 - val_auc_4: 0.7945\n",
            "Epoch 261/400\n",
            " - 0s - loss: 0.2856 - auc_4: 0.7945 - val_loss: 0.3239 - val_auc_4: 0.7946\n",
            "Epoch 262/400\n",
            " - 0s - loss: 0.2839 - auc_4: 0.7947 - val_loss: 0.3239 - val_auc_4: 0.7948\n",
            "Epoch 263/400\n",
            " - 0s - loss: 0.2853 - auc_4: 0.7948 - val_loss: 0.3239 - val_auc_4: 0.7949\n",
            "Epoch 264/400\n",
            " - 0s - loss: 0.2861 - auc_4: 0.7950 - val_loss: 0.3238 - val_auc_4: 0.7951\n",
            "Epoch 265/400\n",
            " - 0s - loss: 0.2832 - auc_4: 0.7952 - val_loss: 0.3238 - val_auc_4: 0.7952\n",
            "Epoch 266/400\n",
            " - 0s - loss: 0.2840 - auc_4: 0.7953 - val_loss: 0.3239 - val_auc_4: 0.7954\n",
            "Epoch 267/400\n",
            " - 0s - loss: 0.2871 - auc_4: 0.7955 - val_loss: 0.3240 - val_auc_4: 0.7955\n",
            "Epoch 268/400\n",
            " - 0s - loss: 0.2863 - auc_4: 0.7956 - val_loss: 0.3241 - val_auc_4: 0.7957\n",
            "\n",
            "Epoch 00268: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
            "Epoch 269/400\n",
            " - 0s - loss: 0.2836 - auc_4: 0.7957 - val_loss: 0.3242 - val_auc_4: 0.7958\n",
            "Epoch 270/400\n",
            " - 0s - loss: 0.2850 - auc_4: 0.7959 - val_loss: 0.3241 - val_auc_4: 0.7960\n",
            "Epoch 271/400\n",
            " - 0s - loss: 0.2870 - auc_4: 0.7960 - val_loss: 0.3239 - val_auc_4: 0.7961\n",
            "Epoch 272/400\n",
            " - 0s - loss: 0.2829 - auc_4: 0.7962 - val_loss: 0.3238 - val_auc_4: 0.7962\n",
            "Epoch 273/400\n",
            " - 0s - loss: 0.2848 - auc_4: 0.7963 - val_loss: 0.3238 - val_auc_4: 0.7964\n",
            "Epoch 274/400\n",
            " - 0s - loss: 0.2854 - auc_4: 0.7965 - val_loss: 0.3238 - val_auc_4: 0.7965\n",
            "Epoch 275/400\n",
            " - 0s - loss: 0.2849 - auc_4: 0.7966 - val_loss: 0.3238 - val_auc_4: 0.7967\n",
            "Epoch 276/400\n",
            " - 0s - loss: 0.2841 - auc_4: 0.7967 - val_loss: 0.3237 - val_auc_4: 0.7968\n",
            "Epoch 277/400\n",
            " - 0s - loss: 0.2833 - auc_4: 0.7969 - val_loss: 0.3239 - val_auc_4: 0.7970\n",
            "Epoch 278/400\n",
            " - 0s - loss: 0.2877 - auc_4: 0.7970 - val_loss: 0.3239 - val_auc_4: 0.7971\n",
            "\n",
            "Epoch 00278: ReduceLROnPlateau reducing learning rate to 2.55999976772614e-10.\n",
            "Epoch 279/400\n",
            " - 0s - loss: 0.2850 - auc_4: 0.7972 - val_loss: 0.3238 - val_auc_4: 0.7972\n",
            "Epoch 280/400\n",
            " - 0s - loss: 0.2831 - auc_4: 0.7973 - val_loss: 0.3239 - val_auc_4: 0.7974\n",
            "Epoch 281/400\n",
            " - 0s - loss: 0.2848 - auc_4: 0.7974 - val_loss: 0.3239 - val_auc_4: 0.7975\n",
            "Epoch 282/400\n",
            " - 0s - loss: 0.2861 - auc_4: 0.7976 - val_loss: 0.3239 - val_auc_4: 0.7976\n",
            "Epoch 283/400\n",
            " - 0s - loss: 0.2850 - auc_4: 0.7977 - val_loss: 0.3240 - val_auc_4: 0.7977\n",
            "Epoch 284/400\n",
            " - 0s - loss: 0.2872 - auc_4: 0.7978 - val_loss: 0.3240 - val_auc_4: 0.7979\n",
            "Epoch 285/400\n",
            " - 0s - loss: 0.2875 - auc_4: 0.7980 - val_loss: 0.3240 - val_auc_4: 0.7980\n",
            "Epoch 286/400\n",
            " - 0s - loss: 0.2850 - auc_4: 0.7981 - val_loss: 0.3239 - val_auc_4: 0.7981\n",
            "Epoch 287/400\n",
            " - 0s - loss: 0.2868 - auc_4: 0.7982 - val_loss: 0.3239 - val_auc_4: 0.7982\n",
            "Epoch 288/400\n",
            " - 0s - loss: 0.2832 - auc_4: 0.7983 - val_loss: 0.3239 - val_auc_4: 0.7984\n",
            "\n",
            "Epoch 00288: ReduceLROnPlateau reducing learning rate to 5.119999424429978e-11.\n",
            "Epoch 289/400\n",
            " - 0s - loss: 0.2845 - auc_4: 0.7984 - val_loss: 0.3239 - val_auc_4: 0.7985\n",
            "Epoch 290/400\n",
            " - 0s - loss: 0.2857 - auc_4: 0.7986 - val_loss: 0.3240 - val_auc_4: 0.7986\n",
            "Epoch 291/400\n",
            " - 0s - loss: 0.2846 - auc_4: 0.7987 - val_loss: 0.3240 - val_auc_4: 0.7987\n",
            "Epoch 292/400\n",
            " - 0s - loss: 0.2830 - auc_4: 0.7988 - val_loss: 0.3240 - val_auc_4: 0.7989\n",
            "Epoch 293/400\n",
            " - 0s - loss: 0.2838 - auc_4: 0.7989 - val_loss: 0.3241 - val_auc_4: 0.7990\n",
            "Epoch 294/400\n",
            " - 0s - loss: 0.2854 - auc_4: 0.7991 - val_loss: 0.3242 - val_auc_4: 0.7991\n",
            "Epoch 295/400\n",
            " - 0s - loss: 0.2858 - auc_4: 0.7992 - val_loss: 0.3240 - val_auc_4: 0.7992\n",
            "Epoch 296/400\n",
            " - 0s - loss: 0.2859 - auc_4: 0.7993 - val_loss: 0.3241 - val_auc_4: 0.7993\n",
            "Epoch 297/400\n",
            " - 0s - loss: 0.2865 - auc_4: 0.7994 - val_loss: 0.3240 - val_auc_4: 0.7995\n",
            "Epoch 298/400\n",
            " - 0s - loss: 0.2840 - auc_4: 0.7995 - val_loss: 0.3241 - val_auc_4: 0.7996\n",
            "\n",
            "Epoch 00298: ReduceLROnPlateau reducing learning rate to 1.0239999126415712e-11.\n",
            "Epoch 299/400\n",
            " - 0s - loss: 0.2854 - auc_4: 0.7996 - val_loss: 0.3240 - val_auc_4: 0.7997\n",
            "Epoch 300/400\n",
            " - 0s - loss: 0.2858 - auc_4: 0.7997 - val_loss: 0.3240 - val_auc_4: 0.7998\n",
            "Epoch 301/400\n",
            " - 0s - loss: 0.2848 - auc_4: 0.7999 - val_loss: 0.3239 - val_auc_4: 0.7999\n",
            "Epoch 302/400\n",
            " - 0s - loss: 0.2861 - auc_4: 0.8000 - val_loss: 0.3240 - val_auc_4: 0.8000\n",
            "Epoch 303/400\n",
            " - 0s - loss: 0.2841 - auc_4: 0.8001 - val_loss: 0.3239 - val_auc_4: 0.8001\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00303: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7g0BvRKTi5Y",
        "colab_type": "text"
      },
      "source": [
        "# Dataset de TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia5Q_9qNpoR0",
        "colab_type": "text"
      },
      "source": [
        "Archivo con los descriptores del dataset de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBOvEnxJo7TT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "24bf6409-4961-4d78-c48a-0987ed6c396c"
      },
      "source": [
        "desc = 'Descriptores_test_new.csv' #Este archivo se obtuvo con la notebook tox21_DescriptorsCalc\n",
        "descriptores_test = pd.read_csv(desc)\n",
        "descriptores_test"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>abonds</th>\n",
              "      <th>atoms</th>\n",
              "      <th>bonds</th>\n",
              "      <th>cansmi</th>\n",
              "      <th>cansmiNS</th>\n",
              "      <th>dbonds</th>\n",
              "      <th>formula</th>\n",
              "      <th>HBA1</th>\n",
              "      <th>HBA2</th>\n",
              "      <th>HBD</th>\n",
              "      <th>InChI</th>\n",
              "      <th>InChIKey</th>\n",
              "      <th>L5</th>\n",
              "      <th>logP</th>\n",
              "      <th>MP</th>\n",
              "      <th>MR</th>\n",
              "      <th>MW</th>\n",
              "      <th>nF</th>\n",
              "      <th>rotors</th>\n",
              "      <th>s</th>\n",
              "      <th>sbonds</th>\n",
              "      <th>smarts</th>\n",
              "      <th>tbonds</th>\n",
              "      <th>title</th>\n",
              "      <th>TPSA</th>\n",
              "      <th>CHARGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.3452</td>\n",
              "      <td>323.4901</td>\n",
              "      <td>193.7180</td>\n",
              "      <td>610.831900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9645</td>\n",
              "      <td>234.5760</td>\n",
              "      <td>76.3992</td>\n",
              "      <td>407.094061</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>167.48</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>21.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.1009</td>\n",
              "      <td>260.0716</td>\n",
              "      <td>87.4097</td>\n",
              "      <td>287.315320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.68</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.4267</td>\n",
              "      <td>127.8196</td>\n",
              "      <td>87.9497</td>\n",
              "      <td>328.355826</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.91</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.1642</td>\n",
              "      <td>121.6301</td>\n",
              "      <td>91.2077</td>\n",
              "      <td>351.847720</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642</th>\n",
              "      <td>642</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2986</td>\n",
              "      <td>14.3068</td>\n",
              "      <td>25.6258</td>\n",
              "      <td>92.160020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>643</th>\n",
              "      <td>643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.4309</td>\n",
              "      <td>57.7851</td>\n",
              "      <td>67.1814</td>\n",
              "      <td>219.281340</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.41</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>644</th>\n",
              "      <td>644</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1273</td>\n",
              "      <td>126.9533</td>\n",
              "      <td>26.4687</td>\n",
              "      <td>116.144960</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>645</th>\n",
              "      <td>645</td>\n",
              "      <td>11.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.3393</td>\n",
              "      <td>221.4786</td>\n",
              "      <td>86.1255</td>\n",
              "      <td>344.259400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.93</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>646</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.7094</td>\n",
              "      <td>26.6394</td>\n",
              "      <td>31.6030</td>\n",
              "      <td>114.165540</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.94</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>647 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  abonds  atoms  bonds  ...  tbonds  title    TPSA  CHARGE\n",
              "0             0     6.0   95.0  102.0  ...     0.0    0.0   72.88       0\n",
              "1             1    10.0   33.0   36.0  ...     0.0    0.0  167.48      -1\n",
              "2             2    21.0   35.0   39.0  ...     0.0    0.0   50.68       0\n",
              "3             3    17.0   42.0   44.0  ...     0.0    0.0   37.91       0\n",
              "4             4    12.0   41.0   42.0  ...     0.0    0.0   71.62       0\n",
              "..          ...     ...    ...    ...  ...     ...    ...     ...     ...\n",
              "642         642     0.0   13.0   12.0  ...     0.0    0.0   59.03       0\n",
              "643         643     0.0   36.0   36.0  ...     0.0    0.0   70.41       0\n",
              "644         644     5.0   11.0   11.0  ...     0.0    0.0   78.59       0\n",
              "645         645    11.0   36.0   38.0  ...     0.0    0.0   85.93       0\n",
              "646         646     5.0   13.0   13.0  ...     0.0    0.0   51.94       0\n",
              "\n",
              "[647 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnTZUgZ_pw8V",
        "colab_type": "text"
      },
      "source": [
        "Obtenemos el vector de clases segun las actividades\n",
        "\n",
        "0 : inactivo\n",
        "\n",
        "1 : activo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd_GI44dTwMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91b7241b-a0b0-46c3-eb45-8187cf814bd5"
      },
      "source": [
        "#Read test targets.\n",
        "actives_f = open(\"nr_er_test_new_activity.txt\", \"r\") #Este archivo se obtuvo de la columna de Actividad del SDF.\n",
        "test_activity = []\n",
        "for i,x in enumerate(actives_f):\n",
        "  if(x[0] != 'x'):\n",
        "    test_activity.append(x[0])\n",
        "  else:\n",
        "    descriptores_test = descriptores_test.drop(i,axis =0)\n",
        "test_activity = [int(i) for i in test_activity]\n",
        "y_test = np.array(test_activity)\n",
        "print(y_test.shape)\n",
        "actives_f.close()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(516,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHMrsRCrp6f5",
        "colab_type": "text"
      },
      "source": [
        "Corroboramos la distribucion de clases en test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS8VkvC_UB2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "b590827f-cdca-4562-d094-ef573feb12c8"
      },
      "source": [
        "#Visualizar activos vs inactivos en Test: \n",
        "activos = sum(y_test)\n",
        "inactivos = sum(y_test == 0)\n",
        "print('Proporcion de activos en el dataset:', activos/(activos+inactivos))\n",
        "indices = ['Activos','Inactivos']\n",
        "activity_df = pd.DataFrame(data = [activos, inactivos], columns = ['Test'], index = indices)\n",
        "activity_df"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proporcion de activos en el dataset: 0.09883720930232558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Activos</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Inactivos</th>\n",
              "      <td>465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Test\n",
              "Activos      51\n",
              "Inactivos   465"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM4fdn2dqSQd",
        "colab_type": "text"
      },
      "source": [
        "Normalizacion de los datos de Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN9k3VAFUVzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b36752ed-1fa4-4175-b105-dbecb201f6e0"
      },
      "source": [
        "#Test Dataset Scale:\n",
        "X_test = desc_scaler.transform(descriptores_test)\n",
        "X_test.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(516, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lHsf4I_qW9F",
        "colab_type": "text"
      },
      "source": [
        "Evaluacion de Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OiV3E0yUpOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04143622-a123-4760-92cb-8b9fb401a16e"
      },
      "source": [
        "from sklearn.metrics import auc, roc_auc_score, accuracy_score, roc_curve\n",
        "#Predict for Test:\n",
        "predicted = model.predict(X_test)\n",
        "#Evaluar metrica AUC en test\n",
        "m = metrics.AUC()\n",
        "m.update_state(y_test,predicted)\n",
        "auc_test = m.result().numpy()\n",
        "\n",
        "print(auc_test)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7678895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ACaxBYOq-5s",
        "colab_type": "text"
      },
      "source": [
        "Para visualizar la matriz de confusión y por ende los valores de VN, FP, FN y VP que permiten una mejor interpretación de los resultados se calcula el umbral óptimo para el cual los valores de Especificidad y Sensibilidad de la curva Roc son mayores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL8p1S2zAaDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f48ffc67-92f0-4226-ce6c-6d811a932755"
      },
      "source": [
        "def Find_Optimal_Cutoff(target, predicted):\n",
        "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
        "    i = np.arange(len(tpr)) \n",
        "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
        "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
        "\n",
        "    return roc_t['threshold'].values\n",
        "\n",
        "threshold = Find_Optimal_Cutoff(y_test,predicted)[0]\n",
        "threshold"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17864324"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gys3Ed57rMvI",
        "colab_type": "text"
      },
      "source": [
        "Con ese umbral se predicen las clases para el dataset de test y se calcula la matriz de confusión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RsxmNa2hY1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSDbqFPP-Ob7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted[predicted<=threshold] = 0\n",
        "predicted[predicted>threshold] = 1\n",
        "predicted = predicted.flatten().astype(int)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80gbKAUwqGwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dbc31f7d-c271-4505-df62-bedf9519ed12"
      },
      "source": [
        "print(confusion_matrix(y_test,predicted))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[317 148]\n",
            " [ 17  34]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m91voZB8sKs4",
        "colab_type": "text"
      },
      "source": [
        "# Discusión y conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08vsstxasWdU",
        "colab_type": "text"
      },
      "source": [
        "Para evaluar el roc_auc score obtenido para el dataset de test (0.768) se lo compara con el del equipo ganador de la competencia Tox21 Data Challenge, el unico equipo en utilizar redes neuronales. Nuestro resultado es comparable con el resultado obtenido por el equipo ganador que fue de 0.810. \n",
        "\n",
        "Creemos que la principal razón de la diferencia entre los resultados puede deberse a la cantidad de descriptores utilizados para la clasificación. En nuestro caso contamos únicamente con 27 descriptores mientras que en el trabajo del equipo ganador se utilizaron mas de mil descriptores. También puede deberse a la elección de los hiperparámetros.\n",
        "\n",
        "Es importante comentar que durante la realización del trabajo nos encontramos con el siguiente inconveniente:\n",
        "\n",
        "Existe una diferencia en la métrica calculada (AUC) durante el entrenamiento y luego del entrenamiento. Esto se evidencio cuando realizamos el calculo del AUC para el dataset de Test, el cual fue considerablemente menor que el calculado durante el entrenamiento para el set de validación. Para verificar esto, recalculamos el AUC para el set de Validación de la misma forma que para Test, obteniendo un resultado distinto al observado durante el entrenamiento.Esta diferencia puede verse al utilizar los metodos predict y evaluate, como se ve a continuacion. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLetRzSYT8p_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5acc161f-c4ed-45d6-9650-f17fd157387c"
      },
      "source": [
        "val_pred = model.predict(X_val)\n",
        "\n",
        "m = metrics.AUC()\n",
        "m.update_state(y_val,val_pred)\n",
        "print('AUC para Val obtenido a partir de las predicciones hechas con predict:', m.result().numpy())\n",
        "\n",
        "auc_evaluate = model.evaluate(X_val, y_val,batch_size=len(y_val),verbose=0)\n",
        "print('AUC para Val obtenido con evaluate:', auc_evaluate[1])\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC para Val obtenido a partir de las predicciones hechas con predict: 0.7619601\n",
            "AUC para Val obtenido con evaluate: 0.8000931739807129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5sRvHs4zcsu",
        "colab_type": "text"
      },
      "source": [
        "El valor de AUC no solo cambia despues del entrenamiento sino que esta variacion no es siempre igual, imposibilitando la comparacion entre modelos distintos. Ademas, un resultado en la validacion no garantiza un resultado similar para el test. Hubo casos en los que se obtuvo un score de AUC de 0.93 para la validacion pero al evaluar el set de Test no superaba el 0.7.\n",
        "\n",
        "Por otro lado, se observo que las metricas de VP, VN, FP y FN daban valores mas altos que la cantidad total de compuestos. Por lo tanto, asumimos que el valor correcto de AUC para comparar el resultado con el de la competencia Tox21 era el obtenido a partir de las predicciones del modelo (utilizando la funcion predict).\n"
      ]
    }
  ]
}