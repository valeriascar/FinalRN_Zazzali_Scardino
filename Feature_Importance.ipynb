{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparacion de notebook y datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eli5\n",
      "  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
      "Requirement already satisfied: graphviz in c:\\users\\meui_\\anaconda3\\lib\\site-packages (from eli5) (0.13.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\meui_\\anaconda3\\lib\\site-packages (from eli5) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\meui_\\anaconda3\\lib\\site-packages (from eli5) (1.12.0)\n",
      "Requirement already satisfied: attrs>16.0.0 in c:\\users\\meui_\\anaconda3\\lib\\site-packages (from eli5) (19.2.0)\n",
      "Collecting tabulate>=0.7.7 (from eli5)\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/f4/770ae9385990f5a19a91431163d262182d3203662ea2b5739d0fcfc080f1/tabulate-0.8.7-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\meui_\\anaconda3\\lib\\site-packages (from eli5) (1.16.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\meui_\\anaconda3\\lib\\site-packages (from eli5) (2.10.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\meui_\\anaconda3\\lib\\site-packages (from eli5) (0.21.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\meui_\\anaconda3\\lib\\site-packages (from jinja2->eli5) (1.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\meui_\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->eli5) (0.13.2)\n",
      "Installing collected packages: tabulate, eli5\n",
      "Successfully installed eli5-0.10.1 tabulate-0.8.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.metrics import AUC, TruePositives, FalsePositives, FalseNegatives\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization, PReLU, ELU, LeakyReLU\n",
    "from keras.layers import Conv2D, AveragePooling2D, BatchNormalization, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras import optimizers, initializers\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.initializers import glorot_uniform, he_uniform, uniform, Constant\n",
    "from keras.constraints import maxnorm\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abonds</th>\n",
       "      <th>atoms</th>\n",
       "      <th>bonds</th>\n",
       "      <th>cansmi</th>\n",
       "      <th>cansmiNS</th>\n",
       "      <th>dbonds</th>\n",
       "      <th>formula</th>\n",
       "      <th>HBA1</th>\n",
       "      <th>HBA2</th>\n",
       "      <th>...</th>\n",
       "      <th>MW</th>\n",
       "      <th>nF</th>\n",
       "      <th>rotors</th>\n",
       "      <th>s</th>\n",
       "      <th>sbonds</th>\n",
       "      <th>smarts</th>\n",
       "      <th>tbonds</th>\n",
       "      <th>title</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>CHARGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>378.312159</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>457.603800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>253.262640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>494.475279</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>474.855700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7692</td>\n",
       "      <td>7692</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>170.232100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7693</td>\n",
       "      <td>7693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.158140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.158140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7695</td>\n",
       "      <td>7695</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291.260621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7696</td>\n",
       "      <td>7696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>398.558340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7697 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  abonds  atoms  bonds  cansmi  cansmiNS  dbonds  formula  \\\n",
       "0              0    11.0   42.0   44.0     0.0       0.0     0.0      0.0   \n",
       "1              1    18.0   69.0   73.0     0.0       0.0     0.0      0.0   \n",
       "2              2    17.0   30.0   32.0     0.0       0.0     0.0      0.0   \n",
       "3              3    12.0   59.0   61.0     0.0       0.0     4.0      0.0   \n",
       "4              4     0.0   92.0   91.0     0.0       0.0     0.0      0.0   \n",
       "...          ...     ...    ...    ...     ...       ...     ...      ...   \n",
       "7692        7692     6.0   21.0   21.0     0.0       0.0     2.0      0.0   \n",
       "7693        7693     0.0   12.0   12.0     0.0       0.0     1.0      0.0   \n",
       "7694        7694     0.0   12.0   12.0     0.0       0.0     1.0      0.0   \n",
       "7695        7695     6.0   32.0   32.0     0.0       0.0     2.0      0.0   \n",
       "7696        7696     0.0   50.0   49.0     0.0       0.0     3.0      0.0   \n",
       "\n",
       "      HBA1  HBA2  ...          MW   nF  rotors    s  sbonds  smarts  tbonds  \\\n",
       "0     19.0   3.0  ...  378.312159  6.0     4.0  0.0    33.0     0.0     0.0   \n",
       "1     39.0   4.0  ...  457.603800  0.0     7.0  0.0    55.0     0.0     0.0   \n",
       "2     18.0   7.0  ...  253.262640  0.0     1.0  0.0    15.0     0.0     0.0   \n",
       "3     28.0   4.0  ...  494.475279  6.0     7.0  0.0    45.0     0.0     0.0   \n",
       "4     64.0   3.0  ...  474.855700  0.0    25.0  0.0    91.0     0.0     0.0   \n",
       "...    ...   ...  ...         ...  ...     ...  ...     ...     ...     ...   \n",
       "7692  12.0   2.0  ...  170.232100  0.0     2.0  0.0    13.0     0.0     0.0   \n",
       "7693   9.0   3.0  ...  102.158140  0.0     0.0  0.0    11.0     0.0     0.0   \n",
       "7694   9.0   3.0  ...  102.158140  0.0     0.0  0.0    11.0     0.0     0.0   \n",
       "7695  19.0   4.0  ...  291.260621  0.0     7.0  0.0    24.0     0.0     0.0   \n",
       "7696  35.0   9.0  ...  398.558340  0.0    16.0  0.0    46.0     0.0     0.0   \n",
       "\n",
       "      title    TPSA  CHARGE  \n",
       "0       0.0   45.15       0  \n",
       "1       0.0   30.93       0  \n",
       "2       0.0  129.62       0  \n",
       "3       0.0   48.78       0  \n",
       "4       0.0   27.69       1  \n",
       "...     ...     ...     ...  \n",
       "7692    0.0   80.74       0  \n",
       "7693    0.0   56.15       0  \n",
       "7694    0.0   56.15       0  \n",
       "7695    0.0  115.41       0  \n",
       "7696    0.0  195.30       0  \n",
       "\n",
       "[7697 rows x 27 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_path = 'Descriptores_nr_er.csv' #Este archivo se obtuvo con la notebook tox21_DescriptorsCalc\n",
    "descriptores = pd.read_csv(desc_path)\n",
    "descriptores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7697,)\n"
     ]
    }
   ],
   "source": [
    "#Read target.\n",
    "actives_f = open(\"nr_er_activity.txt\", \"r\") #Este archivo se obtuvo de la columna de Actividad del SDF.\n",
    "activity = []\n",
    "for x in actives_f:\n",
    "  activity.append(x[0])\n",
    "#activity = activity[1:]\n",
    "activity = [int(i) for i in activity]\n",
    "y = np.array(activity)\n",
    "print(y.shape)\n",
    "actives_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6927, 27)\n",
      "(770, 27)\n",
      "(6927,)\n",
      "(770,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(descriptores.values, y, test_size =0.1,random_state = 42, stratify=activity)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abonds</th>\n",
       "      <th>atoms</th>\n",
       "      <th>bonds</th>\n",
       "      <th>cansmi</th>\n",
       "      <th>cansmiNS</th>\n",
       "      <th>dbonds</th>\n",
       "      <th>formula</th>\n",
       "      <th>HBA1</th>\n",
       "      <th>HBA2</th>\n",
       "      <th>...</th>\n",
       "      <th>MW</th>\n",
       "      <th>nF</th>\n",
       "      <th>rotors</th>\n",
       "      <th>s</th>\n",
       "      <th>sbonds</th>\n",
       "      <th>smarts</th>\n",
       "      <th>tbonds</th>\n",
       "      <th>title</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>CHARGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.867422</td>\n",
       "      <td>0.061204</td>\n",
       "      <td>0.681038</td>\n",
       "      <td>0.628320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.267463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776294</td>\n",
       "      <td>-0.191243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159438</td>\n",
       "      <td>-0.148362</td>\n",
       "      <td>0.746655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.474732</td>\n",
       "      <td>0.113714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.218618</td>\n",
       "      <td>0.061204</td>\n",
       "      <td>-0.696640</td>\n",
       "      <td>-0.695395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.890852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.664650</td>\n",
       "      <td>-0.746224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.858691</td>\n",
       "      <td>-0.148362</td>\n",
       "      <td>-0.522930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.697721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.677815</td>\n",
       "      <td>0.113714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.849975</td>\n",
       "      <td>0.061204</td>\n",
       "      <td>-0.554122</td>\n",
       "      <td>-0.558459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.267463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.520556</td>\n",
       "      <td>-0.191243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.568211</td>\n",
       "      <td>-0.148362</td>\n",
       "      <td>-0.311333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.598879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.421236</td>\n",
       "      <td>0.113714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.431886</td>\n",
       "      <td>0.061204</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>-0.010714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.890852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127869</td>\n",
       "      <td>-0.191243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283662</td>\n",
       "      <td>-0.148362</td>\n",
       "      <td>0.323460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>0.113714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.397894</td>\n",
       "      <td>-0.992992</td>\n",
       "      <td>0.633532</td>\n",
       "      <td>0.719611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560152</td>\n",
       "      <td>-0.468734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225386</td>\n",
       "      <td>-0.148362</td>\n",
       "      <td>-0.946125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.444546</td>\n",
       "      <td>0.113714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    abonds     atoms     bonds  cansmi  cansmiNS    dbonds  \\\n",
       "0   -0.867422  0.061204  0.681038  0.628320     0.0       0.0 -0.267463   \n",
       "1   -0.218618  0.061204 -0.696640 -0.695395     0.0       0.0 -0.890852   \n",
       "2    0.849975  0.061204 -0.554122 -0.558459     0.0       0.0 -0.267463   \n",
       "3   -0.431886  0.061204  0.015952 -0.010714     0.0       0.0 -0.890852   \n",
       "4   -1.397894 -0.992992  0.633532  0.719611     0.0       0.0  0.979316   \n",
       "\n",
       "   formula      HBA1      HBA2  ...        MW        nF    rotors    s  \\\n",
       "0      0.0  0.776294 -0.191243  ...  0.159438 -0.148362  0.746655  0.0   \n",
       "1      0.0 -0.664650 -0.746224  ... -0.858691 -0.148362 -0.522930  0.0   \n",
       "2      0.0 -0.520556 -0.191243  ... -0.568211 -0.148362 -0.311333  0.0   \n",
       "3      0.0  0.127869 -0.191243  ... -0.283662 -0.148362  0.323460  0.0   \n",
       "4      0.0  0.560152 -0.468734  ...  0.225386 -0.148362 -0.946125  0.0   \n",
       "\n",
       "     sbonds  smarts    tbonds  title      TPSA    CHARGE  \n",
       "0  0.686063     0.0 -0.168185    0.0 -0.474732  0.113714  \n",
       "1 -0.697721     0.0 -0.168185    0.0 -0.677815  0.113714  \n",
       "2 -0.598879     0.0 -0.168185    0.0 -0.421236  0.113714  \n",
       "3  0.043592     0.0 -0.168185    0.0 -0.136819  0.113714  \n",
       "4  0.982589     0.0 -0.168185    0.0 -0.444546  0.113714  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "desc_scaler = StandardScaler()\n",
    "X_train = desc_scaler.fit_transform(X_train)\n",
    "Scaled_descriptors = pd.DataFrame(X_train, columns=descriptores.columns)\n",
    "Scaled_descriptors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation Scale:\n",
    "X_val = desc_scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparacion de Modelo final con mejores hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(\n",
    "                learning_rate=0.1,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=1e-7,\n",
    "                amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=85, restore_best_weights = True)\n",
    "reduceLR=ReduceLROnPlateau(monitor='val_loss', \n",
    "                            factor=0.2, \n",
    "                            patience=10, \n",
    "                            verbose=1, \n",
    "                            min_delta=0, \n",
    "                            cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_categorical = enc.fit(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo final utilizado y lo levantamos con la funcion KerasClassifier de sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_base():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(512, input_dim = X_train.shape[1], kernel_initializer='he_uniform', activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512,kernel_regularizer = None, kernel_initializer='he_uniform', activation ='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(512,kernel_regularizer = None,kernel_initializer='he_uniform', activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(512,kernel_regularizer = None,kernel_initializer='he_uniform', activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(512,kernel_regularizer = None,kernel_initializer='he_uniform', activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,kernel_initializer='he_uniform', activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer ,metrics=['accuracy'])    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(\n",
    "                learning_rate=0.1,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=1e-7,\n",
    "                amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = KerasClassifier(build_fn=model_base, batch_size=256, validation_data=(X_val, y_val), epochs=400, verbose=2, shuffle=True, callbacks= [es, reduceLR])    \n",
    "# my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un fit del modelo obtenido conla funcion KerasClassifier de Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6927 samples, validate on 770 samples\n",
      "Epoch 1/400\n",
      " - 2s - loss: 1.1483 - accuracy: 0.7775 - val_loss: 19.5503 - val_accuracy: 0.6013\n",
      "Epoch 2/400\n",
      " - 1s - loss: 0.3926 - accuracy: 0.8691 - val_loss: 3.1866 - val_accuracy: 0.5649\n",
      "Epoch 3/400\n",
      " - 1s - loss: 0.7129 - accuracy: 0.8247 - val_loss: 3.2957 - val_accuracy: 0.1558\n",
      "Epoch 4/400\n",
      " - 1s - loss: 0.3560 - accuracy: 0.8769 - val_loss: 0.9258 - val_accuracy: 0.5701\n",
      "Epoch 5/400\n",
      " - 1s - loss: 0.3107 - accuracy: 0.8841 - val_loss: 0.6911 - val_accuracy: 0.6610\n",
      "Epoch 6/400\n",
      " - 1s - loss: 0.3035 - accuracy: 0.8886 - val_loss: 0.3743 - val_accuracy: 0.8571\n",
      "Epoch 7/400\n",
      " - 1s - loss: 0.3064 - accuracy: 0.8857 - val_loss: 0.3411 - val_accuracy: 0.8753\n",
      "Epoch 8/400\n",
      " - 1s - loss: 0.3048 - accuracy: 0.8888 - val_loss: 0.3158 - val_accuracy: 0.8909\n",
      "Epoch 9/400\n",
      " - 1s - loss: 0.3004 - accuracy: 0.8887 - val_loss: 0.3151 - val_accuracy: 0.8909\n",
      "Epoch 10/400\n",
      " - 1s - loss: 0.3033 - accuracy: 0.8868 - val_loss: 0.3124 - val_accuracy: 0.8948\n",
      "Epoch 11/400\n",
      " - 1s - loss: 0.2925 - accuracy: 0.8959 - val_loss: 0.3073 - val_accuracy: 0.8896\n",
      "Epoch 12/400\n",
      " - 1s - loss: 0.2956 - accuracy: 0.8917 - val_loss: 0.3404 - val_accuracy: 0.8844\n",
      "Epoch 13/400\n",
      " - 1s - loss: 0.3030 - accuracy: 0.8877 - val_loss: 0.3484 - val_accuracy: 0.8922\n",
      "Epoch 14/400\n",
      " - 1s - loss: 0.2928 - accuracy: 0.8927 - val_loss: 0.3418 - val_accuracy: 0.8818\n",
      "Epoch 15/400\n",
      " - 1s - loss: 0.2905 - accuracy: 0.8932 - val_loss: 0.3659 - val_accuracy: 0.8857\n",
      "Epoch 16/400\n",
      " - 1s - loss: 0.2870 - accuracy: 0.8979 - val_loss: 0.3341 - val_accuracy: 0.8922\n",
      "Epoch 17/400\n",
      " - 1s - loss: 0.2986 - accuracy: 0.8914 - val_loss: 0.3328 - val_accuracy: 0.8805\n",
      "Epoch 18/400\n",
      " - 1s - loss: 0.2867 - accuracy: 0.8939 - val_loss: 0.3313 - val_accuracy: 0.8909\n",
      "Epoch 19/400\n",
      " - 1s - loss: 0.2877 - accuracy: 0.8935 - val_loss: 0.3741 - val_accuracy: 0.8935\n",
      "Epoch 20/400\n",
      " - 1s - loss: 0.2833 - accuracy: 0.9000 - val_loss: 0.3420 - val_accuracy: 0.8935\n",
      "Epoch 21/400\n",
      " - 1s - loss: 0.2853 - accuracy: 0.8930 - val_loss: 0.3352 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.020000000298023225.\n",
      "Epoch 22/400\n",
      " - 1s - loss: 0.2789 - accuracy: 0.8979 - val_loss: 0.3391 - val_accuracy: 0.8922\n",
      "Epoch 23/400\n",
      " - 1s - loss: 0.2753 - accuracy: 0.8978 - val_loss: 0.3399 - val_accuracy: 0.8935\n",
      "Epoch 24/400\n",
      " - 1s - loss: 0.2730 - accuracy: 0.9008 - val_loss: 0.3360 - val_accuracy: 0.8922\n",
      "Epoch 25/400\n",
      " - 1s - loss: 0.2699 - accuracy: 0.9043 - val_loss: 0.3279 - val_accuracy: 0.8922\n",
      "Epoch 26/400\n",
      " - 1s - loss: 0.2667 - accuracy: 0.9047 - val_loss: 0.3239 - val_accuracy: 0.8935\n",
      "Epoch 27/400\n",
      " - 1s - loss: 0.2656 - accuracy: 0.9043 - val_loss: 0.3265 - val_accuracy: 0.8935\n",
      "Epoch 28/400\n",
      " - 1s - loss: 0.2669 - accuracy: 0.9034 - val_loss: 0.3300 - val_accuracy: 0.8922\n",
      "Epoch 29/400\n",
      " - 1s - loss: 0.2744 - accuracy: 0.9013 - val_loss: 0.3316 - val_accuracy: 0.8870\n",
      "Epoch 30/400\n",
      " - 1s - loss: 0.2694 - accuracy: 0.9039 - val_loss: 0.3200 - val_accuracy: 0.8896\n",
      "Epoch 31/400\n",
      " - 1s - loss: 0.2676 - accuracy: 0.9070 - val_loss: 0.3237 - val_accuracy: 0.8896\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.003999999910593033.\n",
      "Epoch 32/400\n",
      " - 1s - loss: 0.2653 - accuracy: 0.9062 - val_loss: 0.3179 - val_accuracy: 0.8922\n",
      "Epoch 33/400\n",
      " - 1s - loss: 0.2638 - accuracy: 0.9057 - val_loss: 0.3147 - val_accuracy: 0.8935\n",
      "Epoch 34/400\n",
      " - 1s - loss: 0.2644 - accuracy: 0.9056 - val_loss: 0.3135 - val_accuracy: 0.8948\n",
      "Epoch 35/400\n",
      " - 1s - loss: 0.2631 - accuracy: 0.9059 - val_loss: 0.3135 - val_accuracy: 0.8935\n",
      "Epoch 36/400\n",
      " - 1s - loss: 0.2631 - accuracy: 0.9052 - val_loss: 0.3106 - val_accuracy: 0.8935\n",
      "Epoch 37/400\n",
      " - 1s - loss: 0.2617 - accuracy: 0.9065 - val_loss: 0.3117 - val_accuracy: 0.8922\n",
      "Epoch 38/400\n",
      " - 1s - loss: 0.2620 - accuracy: 0.9075 - val_loss: 0.3107 - val_accuracy: 0.8961\n",
      "Epoch 39/400\n",
      " - 1s - loss: 0.2590 - accuracy: 0.9083 - val_loss: 0.3093 - val_accuracy: 0.8935\n",
      "Epoch 40/400\n",
      " - 1s - loss: 0.2591 - accuracy: 0.9086 - val_loss: 0.3119 - val_accuracy: 0.8974\n",
      "Epoch 41/400\n",
      " - 1s - loss: 0.2586 - accuracy: 0.9093 - val_loss: 0.3145 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0007999999448657036.\n",
      "Epoch 42/400\n",
      " - 1s - loss: 0.2605 - accuracy: 0.9093 - val_loss: 0.3144 - val_accuracy: 0.8974\n",
      "Epoch 43/400\n",
      " - 1s - loss: 0.2595 - accuracy: 0.9096 - val_loss: 0.3137 - val_accuracy: 0.8987\n",
      "Epoch 44/400\n",
      " - 1s - loss: 0.2570 - accuracy: 0.9089 - val_loss: 0.3133 - val_accuracy: 0.8974\n",
      "Epoch 45/400\n",
      " - 1s - loss: 0.2588 - accuracy: 0.9093 - val_loss: 0.3132 - val_accuracy: 0.9000\n",
      "Epoch 46/400\n",
      " - 1s - loss: 0.2565 - accuracy: 0.9119 - val_loss: 0.3129 - val_accuracy: 0.9000\n",
      "Epoch 47/400\n",
      " - 1s - loss: 0.2596 - accuracy: 0.9057 - val_loss: 0.3139 - val_accuracy: 0.8961\n",
      "Epoch 48/400\n",
      " - 1s - loss: 0.2562 - accuracy: 0.9083 - val_loss: 0.3140 - val_accuracy: 0.8987\n",
      "Epoch 49/400\n",
      " - 1s - loss: 0.2554 - accuracy: 0.9069 - val_loss: 0.3140 - val_accuracy: 0.9000\n",
      "Epoch 50/400\n",
      " - 1s - loss: 0.2556 - accuracy: 0.9099 - val_loss: 0.3144 - val_accuracy: 0.9000\n",
      "Epoch 51/400\n",
      " - 1s - loss: 0.2596 - accuracy: 0.9076 - val_loss: 0.3147 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00015999998431652786.\n",
      "Epoch 52/400\n",
      " - 1s - loss: 0.2570 - accuracy: 0.9088 - val_loss: 0.3147 - val_accuracy: 0.9000\n",
      "Epoch 53/400\n",
      " - 1s - loss: 0.2574 - accuracy: 0.9104 - val_loss: 0.3148 - val_accuracy: 0.9000\n",
      "Epoch 54/400\n",
      " - 1s - loss: 0.2581 - accuracy: 0.9086 - val_loss: 0.3143 - val_accuracy: 0.9000\n",
      "Epoch 55/400\n",
      " - 1s - loss: 0.2580 - accuracy: 0.9098 - val_loss: 0.3143 - val_accuracy: 0.9000\n",
      "Epoch 56/400\n",
      " - 1s - loss: 0.2561 - accuracy: 0.9091 - val_loss: 0.3142 - val_accuracy: 0.9039\n",
      "Epoch 57/400\n",
      " - 1s - loss: 0.2568 - accuracy: 0.9091 - val_loss: 0.3140 - val_accuracy: 0.9000\n",
      "Epoch 58/400\n",
      " - 1s - loss: 0.2568 - accuracy: 0.9092 - val_loss: 0.3141 - val_accuracy: 0.9013\n",
      "Epoch 59/400\n",
      " - 1s - loss: 0.2564 - accuracy: 0.9091 - val_loss: 0.3146 - val_accuracy: 0.9000\n",
      "Epoch 60/400\n",
      " - 1s - loss: 0.2544 - accuracy: 0.9124 - val_loss: 0.3146 - val_accuracy: 0.9000\n",
      "Epoch 61/400\n",
      " - 1s - loss: 0.2553 - accuracy: 0.9098 - val_loss: 0.3146 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-05.\n",
      "Epoch 62/400\n",
      " - 1s - loss: 0.2561 - accuracy: 0.9092 - val_loss: 0.3146 - val_accuracy: 0.9000\n",
      "Epoch 63/400\n",
      " - 1s - loss: 0.2575 - accuracy: 0.9086 - val_loss: 0.3146 - val_accuracy: 0.9000\n",
      "Epoch 64/400\n",
      " - 1s - loss: 0.2564 - accuracy: 0.9099 - val_loss: 0.3145 - val_accuracy: 0.9000\n",
      "Epoch 65/400\n",
      " - 1s - loss: 0.2569 - accuracy: 0.9091 - val_loss: 0.3145 - val_accuracy: 0.9000\n",
      "Epoch 66/400\n",
      " - 1s - loss: 0.2582 - accuracy: 0.9092 - val_loss: 0.3147 - val_accuracy: 0.9000\n",
      "Epoch 67/400\n",
      " - 1s - loss: 0.2546 - accuracy: 0.9098 - val_loss: 0.3145 - val_accuracy: 0.9000\n",
      "Epoch 68/400\n",
      " - 1s - loss: 0.2557 - accuracy: 0.9082 - val_loss: 0.3146 - val_accuracy: 0.9000\n",
      "Epoch 69/400\n",
      " - 1s - loss: 0.2548 - accuracy: 0.9105 - val_loss: 0.3141 - val_accuracy: 0.9000\n",
      "Epoch 70/400\n",
      " - 1s - loss: 0.2557 - accuracy: 0.9105 - val_loss: 0.3130 - val_accuracy: 0.9000\n",
      "Epoch 71/400\n",
      " - 1s - loss: 0.2550 - accuracy: 0.9105 - val_loss: 0.3128 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 6.399999256245792e-06.\n",
      "Epoch 72/400\n",
      " - 1s - loss: 0.2576 - accuracy: 0.9106 - val_loss: 0.3133 - val_accuracy: 0.9026\n",
      "Epoch 73/400\n",
      " - 1s - loss: 0.2570 - accuracy: 0.9096 - val_loss: 0.3137 - val_accuracy: 0.9026\n",
      "Epoch 74/400\n",
      " - 1s - loss: 0.2555 - accuracy: 0.9101 - val_loss: 0.3140 - val_accuracy: 0.9000\n",
      "Epoch 75/400\n",
      " - 1s - loss: 0.2566 - accuracy: 0.9086 - val_loss: 0.3144 - val_accuracy: 0.9026\n",
      "Epoch 76/400\n",
      " - 1s - loss: 0.2550 - accuracy: 0.9104 - val_loss: 0.3144 - val_accuracy: 0.9026\n",
      "Epoch 77/400\n",
      " - 1s - loss: 0.2580 - accuracy: 0.9088 - val_loss: 0.3145 - val_accuracy: 0.9026\n",
      "Epoch 78/400\n",
      " - 1s - loss: 0.2578 - accuracy: 0.9086 - val_loss: 0.3142 - val_accuracy: 0.9000\n",
      "Epoch 79/400\n",
      " - 1s - loss: 0.2552 - accuracy: 0.9093 - val_loss: 0.3140 - val_accuracy: 0.9000\n",
      "Epoch 80/400\n",
      " - 1s - loss: 0.2566 - accuracy: 0.9079 - val_loss: 0.3144 - val_accuracy: 0.9000\n",
      "Epoch 81/400\n",
      " - 1s - loss: 0.2559 - accuracy: 0.9093 - val_loss: 0.3141 - val_accuracy: 0.9039\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.2799998330592645e-06.\n",
      "Epoch 82/400\n",
      " - 1s - loss: 0.2578 - accuracy: 0.9089 - val_loss: 0.3135 - val_accuracy: 0.9000\n",
      "Epoch 83/400\n",
      " - 1s - loss: 0.2547 - accuracy: 0.9104 - val_loss: 0.3139 - val_accuracy: 0.9000\n",
      "Epoch 84/400\n",
      " - 1s - loss: 0.2573 - accuracy: 0.9102 - val_loss: 0.3140 - val_accuracy: 0.9000\n",
      "Epoch 85/400\n",
      " - 1s - loss: 0.2572 - accuracy: 0.9095 - val_loss: 0.3140 - val_accuracy: 0.9000\n",
      "Epoch 86/400\n",
      " - 1s - loss: 0.2575 - accuracy: 0.9109 - val_loss: 0.3138 - val_accuracy: 0.9013\n",
      "Epoch 87/400\n",
      " - 1s - loss: 0.2579 - accuracy: 0.9082 - val_loss: 0.3134 - val_accuracy: 0.9000\n",
      "Epoch 88/400\n",
      " - 1s - loss: 0.2576 - accuracy: 0.9091 - val_loss: 0.3129 - val_accuracy: 0.9000\n",
      "Epoch 89/400\n",
      " - 1s - loss: 0.2570 - accuracy: 0.9082 - val_loss: 0.3129 - val_accuracy: 0.9000\n",
      "Epoch 90/400\n",
      " - 1s - loss: 0.2567 - accuracy: 0.9089 - val_loss: 0.3132 - val_accuracy: 0.9000\n",
      "Epoch 91/400\n",
      " - 1s - loss: 0.2541 - accuracy: 0.9108 - val_loss: 0.3132 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 2.559999757067999e-07.\n",
      "Epoch 92/400\n",
      " - 1s - loss: 0.2556 - accuracy: 0.9095 - val_loss: 0.3135 - val_accuracy: 0.9000\n",
      "Epoch 93/400\n",
      " - 1s - loss: 0.2562 - accuracy: 0.9096 - val_loss: 0.3141 - val_accuracy: 0.9000\n",
      "Epoch 94/400\n",
      " - 1s - loss: 0.2576 - accuracy: 0.9093 - val_loss: 0.3139 - val_accuracy: 0.9000\n",
      "Epoch 95/400\n",
      " - 1s - loss: 0.2560 - accuracy: 0.9088 - val_loss: 0.3136 - val_accuracy: 0.9000\n",
      "Epoch 96/400\n",
      " - 1s - loss: 0.2560 - accuracy: 0.9093 - val_loss: 0.3139 - val_accuracy: 0.9000\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00096: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d72c7fa8c8>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda de Features de mayor importancia para el modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función PermutationImportance calcula la media del decrecimiento del score cuando un feature se vuelve ruidoso. La media se realiza sobre el total del numero de iteraciones (n_iter en la función)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# my_model = KerasClassifier(build_fn=basemodel, **sk_params)    \n",
    "# my_model.fit(X,y)\n",
    "\n",
    "\n",
    "perm = PermutationImportance(my_model, cv = 'prefit', refit=False, random_state=1, n_iter = 30).fit(X_val,y_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.68513156e-02, -8.82695455e-02, -1.75437492e-02, -1.57497167e-02,\n",
       "        0.00000000e+00,  0.00000000e+00,  3.11595115e-04,  0.00000000e+00,\n",
       "       -6.65050988e-03,  1.57371270e-05, -4.07874858e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -2.30580385e-02, -9.65000629e-03,\n",
       "       -2.03008939e-02, -1.10663477e-02, -7.52234672e-04, -1.60927861e-02,\n",
       "        0.00000000e+00, -9.76646103e-03,  0.00000000e+00,  8.24625456e-04,\n",
       "        0.00000000e+00, -7.10373914e-03, -4.94145789e-04])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0177\n",
       "                \n",
       "                    &plusmn; 0.0099\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                abonds\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.91%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0107\n",
       "                \n",
       "                    &plusmn; 0.0117\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.09%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0074\n",
       "                \n",
       "                    &plusmn; 0.0096\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HBD\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0072\n",
       "                \n",
       "                    &plusmn; 0.0093\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                logP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0078\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rotors\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0076\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Unnamed: 0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.87%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0049\n",
       "                \n",
       "                    &plusmn; 0.0080\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MW\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0033\n",
       "                \n",
       "                    &plusmn; 0.0043\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bonds\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "                    &plusmn; 0.0042\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                atoms\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.97%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0025\n",
       "                \n",
       "                    &plusmn; 0.0069\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sbonds\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.22%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0023\n",
       "                \n",
       "                    &plusmn; 0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HBA1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0053\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                TPSA\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0023\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                nF\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0017\n",
       "                \n",
       "                    &plusmn; 0.0019\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                tbonds\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.28%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0078\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0023\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CHARGE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0032\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HBA2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                InChIKey\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                smarts\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cansmi\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 7 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(perm, feature_names = Scaled_descriptors.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ranking de importancia obtenido tiene sentido con respecto a la significancia de los features. Los abonds por ejemplo es el número de enlaces aromáticos presentes en el compuesto y es una medida importante para la toxicidad. logP tiene que ver con la lipofilicidad de la molécula y determinante de sus propiedades farmacocinéticas. Por otro lado, descriptores que prácticamente no varían a lo largo de los compuestos como \"smarts\" o \"cansmi\" quedaron por debajo del ranking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3(Proyecto)",
   "language": "python",
   "name": "proyecto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
